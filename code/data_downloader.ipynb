{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from binance_historical_data import BinanceDataDumper\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Found overall tickers: 2371\n",
      "---> Filter to asked tickers: 1\n",
      "------> Tickers left: 1\n",
      "Download full data for 1 tickers: \n",
      "---> Data will be saved here: /Users/johnz/Library/CloudStorage/GoogleDrive-john23@berkeley.edu/My Drive/CryptoFutures/data/spot\n",
      "---> Data Frequency: 1m\n",
      "---> Start Date: 20170101\n",
      "---> End Date: 20231201\n"
     ]
    },
    {
     "data": {
      "text/plain": "Tickers:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64f0f2715cc54c168942d65d8e07aaa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "monthly files to download:   0%|          | 0/76 [00:00<?, ?files/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c08943da6c5435e9527030119593c26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "daily files to download: 0files [00:00, ?files/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7525cb025d6344ad867bdc345a13684e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to dump data for 1 tickers:\n",
      "---> For BTCUSDT new data saved for: 75 months 0 days\n"
     ]
    }
   ],
   "source": [
    "data_dumper = BinanceDataDumper(\n",
    "    path_dir_where_to_dump = '../data/',\n",
    "    asset_class = 'spot',\n",
    "    data_type = 'klines',\n",
    "    data_frequency = '1m'\n",
    ")\n",
    "x = data_dumper.dump_data(\n",
    "    tickers = ['BTCUSDT'],\n",
    "    date_start = None,\n",
    "    date_end = None,\n",
    "    is_to_update_existing = True,\n",
    "    # tickers_to_exclude = [\"UST\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def process_klines_data(columns, token_lists, time: str):\n",
    "    \"\"\"\n",
    "    futures\n",
    "    :param columns: for data columns\n",
    "    :param token_lists: tokens to get data for\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = pathlib.Path.cwd().parent / 'data' / \"futures\" / 'um' / 'monthly' / 'klines'\n",
    "    for token in token_lists:\n",
    "        try:\n",
    "            files = path / token / f'{time}'\n",
    "            csv_files = files.glob('*.csv')\n",
    "            dfs = []\n",
    "            for file in csv_files:\n",
    "                df = pd.read_csv(file, index_col=None, names=columns)\n",
    "                idx = df.index[df['open_time'] != 'open_time']\n",
    "                df = df.loc[idx].reset_index(drop=True)\n",
    "                for col in columns:\n",
    "                    df[col] = df[col].astype(float)\n",
    "                dfs.append(df)\n",
    "            df_all = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f'Error for {token}: {e}')\n",
    "    return df_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_klines_data_spot(columns, token : str, time: str):\n",
    "    \"\"\"\n",
    "    futures\n",
    "    :param columns: for data columns\n",
    "    :param token: single token to get data for (ie: BTCUSDT)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    monthly_path = pathlib.Path.cwd().parent / 'data' / \"spot\" / 'monthly' / 'klines'\n",
    "    daily_path = pathlib.Path.cwd().parent / 'data' / \"spot\" / 'daily' / 'klines'\n",
    "    all_paths = [monthly_path, daily_path]\n",
    "    # for token in token_lists:\n",
    "    df_final = []\n",
    "    for path in all_paths:\n",
    "            try:\n",
    "                files = path / token / f'{time}'\n",
    "                csv_files = files.glob('*.csv')\n",
    "                dfs = []\n",
    "                for file in tqdm(csv_files):\n",
    "                    df = pd.read_csv(file, index_col=None, names=columns)\n",
    "                    idx = df.index[df['open_time'] == 'open_time']\n",
    "                    if idx.shape[0] > 0:\n",
    "                        print(f'Number of incorrect rows: {idx.shape} for {file}')\n",
    "                    # df = df.loc[idx].reset_index(drop=True)\n",
    "                    for col in columns:\n",
    "                        df[col] = df[col].astype(float)\n",
    "                    dfs.append(df)\n",
    "                print(len(dfs))\n",
    "                df_all = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "                df_final.append(df_all)\n",
    "            except Exception as e:\n",
    "                print(f'Error for {token}: {e}')\n",
    "    df_final = pd.concat(df_final, axis = 0)\n",
    "    df_final = df_final.drop_duplicates(subset = ['open_time'])\n",
    "    return df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# columns = ['open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "#            'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "#            'taker_buy_base_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "#\n",
    "# df_all = process_klines_data_spot(columns, 'BTCUSDT')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from ta import add_all_ta_features\n",
    "def load_klines_data(universe, columns, save = True, time = '1m'):\n",
    "    dfs = {}\n",
    "    sample = {}\n",
    "    for token in tqdm(universe):\n",
    "        df = process_klines_data_spot(columns, token, time)\n",
    "        df['open_time'] = pd.to_datetime(df['open_time'], unit = 'ms')\n",
    "        df['close_time'] = pd.to_datetime(df['close_time'], unit = 'ms')\n",
    "        df['token'] = token\n",
    "        df = df.sort_values(by = 'open_time', ignore_index = True)\n",
    "        df = add_all_ta_features(df, open = 'open', high = 'high', low = 'low',\n",
    "                                 close = 'close', volume = 'volume', fillna = True)\n",
    "        if save:\n",
    "            df.to_feather(f'../data/processed_data/{token}_{time}_spot.feather')\n",
    "        dfs[token] = df\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "# from factor_util import *\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "# from factor_util import *\n",
    "from joblib import dump, load\n",
    "import bittensor as bt\n",
    "\n",
    "def hullMA(x, n = 50):\n",
    "    sma1 = x.rolling(n,  min_periods = 1).mean()\n",
    "    sma2 = x.rolling(int(n/2),  min_periods = 1).mean()\n",
    "    out = (2 * sma1 - sma2).rolling(int(np.sqrt(n)), min_periods = 1).mean()\n",
    "    return x - out\n",
    "\n",
    "def calculate_corr(df, ta_features = None, columns = None, groupby = True):\n",
    "    if ta_features is None:\n",
    "        skip_features = ['returns_5m', 'open_time', 'close_time', 'target_15m', 'ignore', 'token']\n",
    "        features = [x for x in df.columns if x not in skip_features]\n",
    "        ta_features = [x for x in df.columns if x not in skip_features and x not in columns]\n",
    "    if groupby:\n",
    "        tgt_corr = df.groupby(['token'])[ta_features + ['target_15m']].corr()\n",
    "    else:\n",
    "        tgt_corr = df[ta_features + ['target_15m']].corr()\n",
    "    return tgt_corr\n",
    "\n",
    "def calculate_vol_price_corr(df, windows = [5, 15, 30, 60, 120]):\n",
    "    for window in windows:\n",
    "        df[f'vol_price_corr_{window}'] = df['close'].rolling(window, min_periods = 1).corr(df['volume'])\n",
    "    return df\n",
    "\n",
    "def get_cols_for_corr(df, str_idx):\n",
    "    return df.columns[df.columns.str.startswith(str_idx)].tolist()\n",
    "\n",
    "def transform_time(df):\n",
    "    day = 24 * 60\n",
    "    hour_float = df['open_time'].dt.hour + df['open_time'].dt.minute/60\n",
    "    df['sin_hour'] = np.sin(2.0 * np.pi * hour_float/24)\n",
    "    df['cos_hour'] = np.cos(2.0 * np.pi * hour_float/24)\n",
    "    df['Day_sin'] = np.sin(df['open_time'].dt.day * (2 * np.pi / 31))\n",
    "    df['Day_cos'] = np.cos(df['open_time'].dt.day * (2 * np.pi / 31))\n",
    "    df['month_sin'] = np.sin(df['open_time'].dt.month * (2 * np.pi / 12))\n",
    "    df['month_cos'] = np.cos(df['open_time'].dt.month * (2 * np.pi / 12))\n",
    "    return df\n",
    "\n",
    "def calc_sma_diff_test(close, timeperiod_short, timeperiod_long):\n",
    "    res_short = close.rolling(window = timeperiod_short, min_periods = 1).mean()\n",
    "    res_long = close.rolling(window = timeperiod_long, min_periods = 1).mean()\n",
    "    res = (res_long - res_short) / res_long\n",
    "    return res\n",
    "\n",
    "def load_metrics_data(ticker):\n",
    "    df_metrics = pd.read_feather(f'../data/processed_metrics/{ticker}_1m.feather')\n",
    "    df_metrics['create_time'] = pd.to_datetime(df_metrics['create_time'], format = 'mixed')\n",
    "    return df_metrics\n",
    "\n",
    "def gen_cross_features(x, lag = 60):\n",
    "    \"\"\"\n",
    "    calculate cross features with other assets if any\n",
    "    :param x:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lag_arr = np.ones(lag)\n",
    "    conv_arr = np.convolve(x, lag_arr / lag, mode = 'valid')\n",
    "    app_arr = np.append(conv_arr, np.ones(lag - 1))\n",
    "    roll_arr = np.roll(app_arr, lag - 1)\n",
    "    div_arr = np.log(x / roll_arr)\n",
    "    return div_arr\n",
    "\n",
    "def log_return_np(x):\n",
    "    return np.log(x / x.shift(60)).fillna(0)\n",
    "\n",
    "\n",
    "def generate_features(df, time : int):\n",
    "    directory = '../data/processed_data/'\n",
    "\n",
    "    # df = pd.concat([df_btc, df_eth], axis = 0, ignore_index = True)\n",
    "    df = df.sort_values(by = ['open_time'], ignore_index = True)\n",
    "    # calculate next 15min returns (ie: current open_time is 2020-01-01 00:00:00,\n",
    "    # then return is from 2020-01-01 00:01:00 - 2020-01-01 00:16:00\n",
    "\n",
    "    # bt.logging.debug(f'Computing sma')\n",
    "    times = [(10, '10m'), (15, '15m'), (30, '30m'), (60, '60m'), (120, '120m'),\n",
    "         (240, '240m'), (480, '480m'), (720, '720m'), (1440, '1440m'),\n",
    "         (2880, '2880m')]\n",
    "    # bt.logging.debug(f'Computing sma')\n",
    "    lags = [60]\n",
    "    for lag in lags:\n",
    "        df[f'log_close/mean_{lag}'] = gen_cross_features(df['close'], lag=lag)\n",
    "        df[f'log_return_{lag}'] = log_return_np(df['close'])\n",
    "    df['mid_diff'] = (df['close'] - df['open']) / ((df['high'] - df['low']) + 0.001)\n",
    "\n",
    "    sma_lags = [5, 15, 30, 60, 120, 240, 800]\n",
    "    for sma_lag in sma_lags:\n",
    "        df[f'sma{sma_lag}'] = (df['close'].rolling(sma_lag, min_periods=1).mean())\n",
    "        df[f'sma{sma_lag}'] = (df[f'sma{sma_lag}'] / df['close']) - 1\n",
    "        df[f'return{sma_lag}'] = df['close'].pct_change(sma_lag)\n",
    "        df[f'volume_change_{sma_lag}'] = df['volume'].pct_change(sma_lag)\n",
    "\n",
    "    hull_lags = [76, 240, 800]\n",
    "    for hull_lag in hull_lags:\n",
    "        df[f'hull_{hull_lag}'] = hullMA(df['close'], hull_lag)\n",
    "\n",
    "    fibo_list = [55, 210, 340, 890, 3750]\n",
    "    for num in fibo_list:\n",
    "        df[f'log_return_{num}'] = np.log(df['close']).diff().rolling(num, min_periods=1).mean().ffill().bfill()\n",
    "\n",
    "    df = transform_time(df)\n",
    "    sma_diff_windows = [(12, 26), (12*4*4, 24*4*4), (12*4*4*4, 24*4*4*4), (12*4*4*4*4, 24*4*4*4*4), (12*4*4*4*4*4, 24*4*4*4*4*4)]\n",
    "\n",
    "    for short_win, long_win in sma_diff_windows:\n",
    "        df[f'sma_diff_{short_win}'] = calc_sma_diff_test(df['close'], int(short_win), int(long_win))\n",
    "\n",
    "    df[f'sma_diff_vol_{12 * 4 * 4}'] = calc_sma_diff_test(df['volume'], 12 * 4 * 4, 24 * 4 * 4)\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_features_new(df, time : int):\n",
    "    directory = '../data/processed_data/'\n",
    "\n",
    "    # df = pd.concat([df_btc, df_eth], axis = 0, ignore_index = True)\n",
    "    df = df.sort_values(by = ['open_time'], ignore_index = True)\n",
    "    # calculate next 15min returns (ie: current open_time is 2020-01-01 00:00:00,\n",
    "    # then return is from 2020-01-01 00:01:00 - 2020-01-01 00:16:00\n",
    "\n",
    "    # bt.logging.debug(f'Computing sma')\n",
    "    times = [(10, '10m'), (15, '15m'), (30, '30m'), (60, '60m'), (120, '120m'),\n",
    "         (240, '240m'), (480, '480m'), (720, '720m'), (1440, '1440m'),\n",
    "         (2880, '2880m')]\n",
    "    # bt.logging.debug(f'Computing sma')\n",
    "    lags = [(x // time, y) for x, y in times]\n",
    "    for lag, label in lags:\n",
    "        df[f'log_close/mean_{lag}'] = gen_cross_features(df['close'], lag=lag)\n",
    "        df[f'log_return_{lag}'] = log_return_np(df['close'])\n",
    "    df['mid_diff'] = (df['close'] - df['open']) / ((df['high'] - df['low']) + 0.001)\n",
    "\n",
    "    for sma_lag, label in lags:\n",
    "        df[f'sma{sma_lag}'] = (df['close'].rolling(sma_lag, min_periods=1).mean())\n",
    "        df[f'sma{sma_lag}'] = (df[f'sma{sma_lag}'] / df['close']) - 1\n",
    "        df[f'return{sma_lag}'] = df['close'].pct_change(sma_lag)\n",
    "        df[f'volume_change_{sma_lag}'] = df['volume'].pct_change(sma_lag)\n",
    "\n",
    "    for hull_lag, label in lags:\n",
    "        df[f'hull_{hull_lag}'] = hullMA(df['close'], hull_lag)\n",
    "\n",
    "    for num, label in lags:\n",
    "        df[f'log_return_{num}'] = np.log(df['close']).diff().rolling(num, min_periods=1).mean().ffill().bfill()\n",
    "\n",
    "    df = transform_time(df)\n",
    "    sma_diff_windows = [(12, 26), (12*4*4, 24*4*4), (12*4*4*4, 24*4*4*4), (12*4*4*4*4, 24*4*4*4*4), (12*4*4*4*4*4, 24*4*4*4*4*4)]\n",
    "\n",
    "    for short_win, long_win in sma_diff_windows:\n",
    "        df[f'sma_diff_{short_win}'] = calc_sma_diff_test(df['close'], int(short_win), int(long_win))\n",
    "\n",
    "    df[f'sma_diff_vol_{12 * 4 * 4}'] = calc_sma_diff_test(df['volume'], 12 * 4 * 4, 24 * 4 * 4)\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001B[A\n",
      "2it [00:00, 11.75it/s]\u001B[A\n",
      "4it [00:00, 13.75it/s]\u001B[A\n",
      "6it [00:00, 14.14it/s]\u001B[A\n",
      "8it [00:00, 14.04it/s]\u001B[A\n",
      "10it [00:00, 13.99it/s]\u001B[A\n",
      "12it [00:00, 14.05it/s]\u001B[A\n",
      "14it [00:01, 14.19it/s]\u001B[A\n",
      "16it [00:01, 14.53it/s]\u001B[A\n",
      "18it [00:01, 14.42it/s]\u001B[A\n",
      "20it [00:01, 14.60it/s]\u001B[A\n",
      "22it [00:01, 14.54it/s]\u001B[A\n",
      "24it [00:01, 15.03it/s]\u001B[A\n",
      "26it [00:01, 15.43it/s]\u001B[A\n",
      "28it [00:01, 15.32it/s]\u001B[A\n",
      "30it [00:02, 15.02it/s]\u001B[A\n",
      "32it [00:02, 15.13it/s]\u001B[A\n",
      "34it [00:02, 15.19it/s]\u001B[A\n",
      "37it [00:02, 16.53it/s]\u001B[A\n",
      "39it [00:02, 15.72it/s]\u001B[A\n",
      "41it [00:02, 15.32it/s]\u001B[A\n",
      "43it [00:02, 15.15it/s]\u001B[A\n",
      "45it [00:03, 15.25it/s]\u001B[A\n",
      "47it [00:03, 14.97it/s]\u001B[A\n",
      "49it [00:03, 15.01it/s]\u001B[A\n",
      "51it [00:03, 14.96it/s]\u001B[A\n",
      "53it [00:03, 14.69it/s]\u001B[A\n",
      "55it [00:03, 14.61it/s]\u001B[A\n",
      "57it [00:03, 14.88it/s]\u001B[A\n",
      "59it [00:03, 14.86it/s]\u001B[A\n",
      "61it [00:04, 15.07it/s]\u001B[A\n",
      "63it [00:04, 15.21it/s]\u001B[A\n",
      "65it [00:04, 15.42it/s]\u001B[A\n",
      "67it [00:04, 15.19it/s]\u001B[A\n",
      "69it [00:04, 15.30it/s]\u001B[A\n",
      "71it [00:04, 15.16it/s]\u001B[A\n",
      "73it [00:04, 15.16it/s]\u001B[A\n",
      "75it [00:05, 14.93it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001B[A\n",
      "10it [00:00, 99.79it/s]\u001B[A\n",
      "29it [00:00, 101.69it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnz/anaconda3/envs/python310/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n",
      "100%|██████████| 1/1 [12:21<00:00, 741.53s/it]\n"
     ]
    }
   ],
   "source": [
    "universe = ['BTCUSDT']\n",
    "columns_futures = ['open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "           'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "           'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume',\n",
    "           'ignore']\n",
    "\n",
    "columns_spot = ['open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "           'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "           'taker_buy_base_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "\n",
    "path = pathlib.Path.cwd().parent / 'data' / 'processed_futures'\n",
    "dfs = load_klines_data(universe, columns_spot, time = '1m')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_spot = dfs['BTCUSDT'].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df_feature = generate_features(df_spot, time = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "features_to_remove = ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
    "                      'quote_asset_volume', 'ignore', 'taker_buy_base_volume', 'taker_buy_quote_asset_volume',\n",
    "                      'token']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "features = [x for x in df_feature.columns if x not in features_to_remove]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [19:33<00:00, 167.59s/it]\n"
     ]
    }
   ],
   "source": [
    "corrs = {}\n",
    "freq = [(10, '10m'), (15, '15m'), (30, '30m'), (60, '60m'), (120, '120m'),\n",
    "         (240, '240m'), (480, '480m')]\n",
    "for time, label in tqdm(freq):\n",
    "    df_feature[f'target_{label}'] = df_feature['close'].pct_change(-1)\n",
    "    corr = df_feature[features + [f'target_{label}']].corr()[f'target_{label}']\n",
    "    df_feature = df_feature.drop([f'target_{label}'], axis = 1)\n",
    "    corrs[label] = corr.copy()\n",
    "\n",
    "for k, v in corrs.items():\n",
    "    v.to_csv(f'../output/feature_corr_1m/{k}_corr.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "corrs_all = pd.concat(list(corrs.values()), axis = 1)\n",
    "labels = [f'target_{x[1]}' for x in freq]\n",
    "keep_idx = [x for x in corrs_all.index if x not in labels]\n",
    "mean_corr = corrs_all.mean(axis = 1).abs().loc[keep_idx].sort_values(ascending = False)\n",
    "mean_corr.to_csv('../output/feature_corr_1m/mean_corr.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnz/anaconda3/envs/python310/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "df_feature.to_feather('../data/df_btc_with_features_1m_spot.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New Feature Generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001B[A\n",
      "5it [00:00, 49.90it/s]\u001B[A\n",
      "11it [00:00, 53.43it/s]\u001B[A\n",
      "17it [00:00, 54.70it/s]\u001B[A\n",
      "23it [00:00, 56.69it/s]\u001B[A\n",
      "29it [00:00, 57.31it/s]\u001B[A\n",
      "35it [00:00, 57.90it/s]\u001B[A\n",
      "41it [00:00, 58.19it/s]\u001B[A\n",
      "48it [00:00, 60.56it/s]\u001B[A\n",
      "55it [00:00, 59.91it/s]\u001B[A\n",
      "61it [00:01, 59.67it/s]\u001B[A\n",
      "67it [00:01, 58.36it/s]\u001B[A\n",
      "75it [00:01, 58.19it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001B[A\n",
      "29it [00:00, 189.19it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnz/anaconda3/envs/python310/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n",
      "100%|██████████| 1/1 [02:30<00:00, 150.06s/it]\n"
     ]
    }
   ],
   "source": [
    "universe = ['BTCUSDT']\n",
    "columns_futures = ['open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "           'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "           'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume',\n",
    "           'ignore']\n",
    "\n",
    "columns_spot = ['open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "           'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "           'taker_buy_base_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "\n",
    "path = pathlib.Path.cwd().parent / 'data' / 'processed_futures'\n",
    "dfs = load_klines_data(universe, columns_spot, time = '5m')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_spot = dfs['BTCUSDT'].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_feature = generate_features_new(df_spot, time = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "features_to_remove = ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
    "                      'quote_asset_volume', 'ignore', 'taker_buy_base_volume', 'taker_buy_quote_asset_volume',\n",
    "                      'token']\n",
    "features = [x for x in df_feature.columns if x not in features_to_remove]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:02<00:00, 34.64s/it]\n"
     ]
    }
   ],
   "source": [
    "corrs = {}\n",
    "freq = [(10, '10m'), (15, '15m'), (30, '30m'), (60, '60m'), (120, '120m'),\n",
    "         (240, '240m'), (480, '480m')]\n",
    "\n",
    "for time, label in tqdm(freq):\n",
    "    df_feature[f'target_{label}'] = df_feature['close'].pct_change(-1)\n",
    "    corr = df_feature[features + [f'target_{label}']].corr()[f'target_{label}']\n",
    "    df_feature = df_feature.drop([f'target_{label}'], axis = 1)\n",
    "    corrs[label] = corr.copy()\n",
    "\n",
    "for k, v in corrs.items():\n",
    "    v.to_csv(f'../output/feature_corr/{k}_corr_new_features.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "corrs_all = pd.concat(list(corrs.values()), axis = 1)\n",
    "labels = [f'target_{x[1]}' for x in freq]\n",
    "keep_idx = [x for x in corrs_all.index if x not in labels]\n",
    "mean_corr = corrs_all.mean(axis = 1).abs().loc[keep_idx].sort_values(ascending = False)\n",
    "mean_corr.to_csv('../output/feature_corr/mean_corr_new_features.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "sma3                0.059828\nsma2                0.057268\nothers_dlr          0.056960\nothers_dr           0.056663\nlog_return_2        0.052969\n                      ...   \nDay_sin             0.000333\nvolume_obv          0.000241\nmonth_sin           0.000201\nvolatility_kcp      0.000126\nvolume_change_48    0.000097\nLength: 160, dtype: float64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_corr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnz/anaconda3/envs/python310/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "df_feature.to_feather('../data/df_btc_with_features_5m_spot_new_features.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from binance.spot import Spot\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "exchange_key = 'HHwPdDKvCO3zxbLqQbjxcb0N2wDNDs2aD5aIz3M3GsuiIntsgfV0wWWIaqfnKriw'\n",
    "end_time = round(time.time() * 1000)\n",
    "end_datetime = datetime.fromtimestamp(end_time / 1000.0)\n",
    "\n",
    "\n",
    "client = Spot(api_key = exchange_key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "btc_data = client.klines(symbol = 'BTCUSDT', interval = '5m', limit = 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m kline \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mklines(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBTCUSDT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m5m\u001B[39m\u001B[38;5;124m'\u001B[39m, endTime \u001B[38;5;241m=\u001B[39m end_time, limit \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m      9\u001B[0m columns_spot \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen_time\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhigh\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlow\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvolume\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     10\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose_time\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquote_asset_volume\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber_of_trades\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     11\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtaker_buy_base_volume\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtaker_buy_quote_asset_volume\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 13\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mDataFrame(kline, columns \u001B[38;5;241m=\u001B[39m columns_spot)\n\u001B[1;32m     14\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen_time\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen_time\u001B[39m\u001B[38;5;124m'\u001B[39m], unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mms\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose_time\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose_time\u001B[39m\u001B[38;5;124m'\u001B[39m], unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mms\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "exchange_key = 'HHwPdDKvCO3zxbLqQbjxcb0N2wDNDs2aD5aIz3M3GsuiIntsgfV0wWWIaqfnKriw'\n",
    "end_time = round(time.time() * 1000)\n",
    "end_datetime = datetime.fromtimestamp(end_time / 1000.0)\n",
    "\n",
    "client = Spot(api_key = exchange_key)\n",
    "\n",
    "kline = client.klines(\"BTCUSDT\", '5m', endTime = end_time, limit = 1000)\n",
    "\n",
    "columns_spot = ['open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "                'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                'taker_buy_base_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "\n",
    "df = pd.DataFrame(kline, columns = columns_spot)\n",
    "df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_prev = pd.read_feather('../data/df_btc_with_features_5m_spot.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cols = pd.DataFrame(df_prev.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "               0\n0      open_time\n1           open\n2           high\n3            low\n4          close\n..           ...\n174  target_420m\n175  close_90lag\n176  target_450m\n177  close_96lag\n178  target_480m\n\n[179 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>open_time</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>high</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>close</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>target_420m</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>close_90lag</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>target_450m</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>close_96lag</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>target_480m</td>\n    </tr>\n  </tbody>\n</table>\n<p>179 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}