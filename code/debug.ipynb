{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "List of Ideas:\n",
    "- See bookmarks:\n",
    "- Automating Feature Engineering (Part II)\n",
    "- Use LightGBM for feature importance (Crypto Forecasting - lgbm feval+feature importance)\n",
    "- Crypto Forecasting - Common Factors\n",
    "- Correlation as loss function ? https://www.kaggle.com/competitions/open-problems-multimodal/discussion/347595#1916337\n",
    "-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.python.keras.backend as K\n",
    "import tensorflow.python.keras.layers as layers\n",
    "from tensorflow.python.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls=1e-2, lr=1e-3):\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x0 = tf.keras.layers.BatchNormalization()(inp)\n",
    "\n",
    "    encoder = tf.keras.layers.GaussianNoise(dropout_rates[0])(x0)\n",
    "    encoder = tf.keras.layers.Dense(hidden_units[0])(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Activation('swish')(encoder)\n",
    "\n",
    "    decoder = tf.keras.layers.Dropout(dropout_rates[1])(encoder)\n",
    "    decoder = tf.keras.layers.Dense(num_columns, name='decoder')(decoder)\n",
    "\n",
    "    x_ae = tf.keras.layers.Dense(hidden_units[1])(decoder)\n",
    "    x_ae = tf.keras.layers.BatchNormalization()(x_ae)\n",
    "    x_ae = tf.keras.layers.Activation('swish')(x_ae)\n",
    "    x_ae = tf.keras.layers.Dropout(dropout_rates[2])(x_ae)\n",
    "\n",
    "    out_ae = tf.keras.layers.Dense(num_labels, activation='sigmoid', name='ae_action')(x_ae)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x0, encoder])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[3])(x)\n",
    "\n",
    "    for i in range(2, len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('swish')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 2])(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(num_labels, activation='softmax', name='action')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=[decoder, out_ae, out])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss={'decoder': tf.keras.losses.MeanSquaredError(),\n",
    "                        'ae_action': tf.keras.losses.CategoricalCrossentropy(),\n",
    "                        'action': tf.keras.losses.CategoricalCrossentropy(),\n",
    "                        },\n",
    "                  metrics={'decoder': tf.keras.metrics.MeanAbsoluteError(name='MAE'),\n",
    "                           'ae_action': tf.keras.metrics.AUC(name='AUC'),\n",
    "                           'action': tf.keras.metrics.AUC(name='AUC'),\n",
    "                           },\n",
    "                  )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "def create_model(n_in, n_out, layers, dropout_rate, optimizer, metrics):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (n_in, ))\n",
    "\n",
    "    x=inp\n",
    "    for i,hidden_units in enumerate(layers):\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        if i>0:\n",
    "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "        else:\n",
    "            x = tf.keras.layers.Dropout(.01)(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units)(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(n_out, activation = 'softmax', name = 'action')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics = metrics,\n",
    "#                   run_eagerly=True\n",
    "                 )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class ValScore(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data,dates,weights,targs):\n",
    "        super().__init__()\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.dates, self.weights, self.targs = dates, weights, targs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred=self.model(self.X_val,training = False).numpy()\n",
    "        aoc = roc_auc_score(self.y_val, y_pred,average=None)\n",
    "        action=(y_pred.mean(1)>0.5).astype('int8')\n",
    "        score=utility_score_bincount(self.dates,self.weights,self.targs,action)\n",
    "        print(f\"AOC scores: {aoc}, t: {score[0]:.2f}, Utility score: {score[1]:.0f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import tscv\n",
    "\n",
    "def generate_label(df, threshold = 0.002):\n",
    "    df['label'] = 0\n",
    "    df.loc[(df['target_15m'] <= -1*threshold), 'label'] = 1\n",
    "    df.loc[(df['target_15m'] >= threshold), 'label'] = 2\n",
    "    return df\n",
    "\n",
    "def get_na_features(df, train_features):\n",
    "    tmp = pd.DataFrame(df[train_features].isnull().sum())\n",
    "    tmp = tmp[tmp[0] > 0].reset_index()\n",
    "    tmp.columns = ['feat', 'cnt']\n",
    "    tmp = tmp.sort_values('cnt')\n",
    "    feat_groups = dict(tmp.groupby('cnt')['feat'].agg(lambda x: list(x)))\n",
    "    return feat_groups\n",
    "\n",
    "def normalize_float_columns(df, features):\n",
    "  float_cols = df[features].select_dtypes(include = [float]).columns\n",
    "  grouped_df = df.groupby(['token'])\n",
    "  for col in float_cols:\n",
    "      df[col] = grouped_df[col].transform(lambda x: (x - x.mean()) / (x.std()))\n",
    "  df[float_cols] = (df[float_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0))\n",
    "  return df\n",
    "\n",
    "class Params: pass\n",
    "param = Params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train = False\n",
    "df = pd.read_feather('../data/df_btc_eth_with_features.feather')\n",
    "cols_to_drop = ['open_time', 'close_time', 'ignore',\n",
    "                'create_time', 'symbol', 'returns', 'returns_5m',\n",
    "                'open', 'high', 'low', 'close', 'target_15m', 'label']\n",
    "\n",
    "df = df.sort_values(by='open_time', ignore_index=True)\n",
    "df = generate_label(df, threshold=0.002)\n",
    "\n",
    "start_time = df['open_time'].min()\n",
    "end_time = df['open_time'].max()\n",
    "dates = df['open_time'].unique()\n",
    "n = len(dates)\n",
    "train_idx = int(0.7 * n)\n",
    "valid_idx = int(0.2 * n)\n",
    "train_end = dates[train_idx]\n",
    "valid_end = dates[valid_idx]\n",
    "\n",
    "train_df = df.loc[df['open_time'] < train_end].reset_index(drop=True)\n",
    "valid_df = df.loc[(train_end <= df['open_time']) & (df['open_time'] < valid_end)].reset_index(drop=True)\n",
    "test_df = df.loc[(df['open_time'] >= valid_end)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_features = [x for x in df.columns if (x not in cols_to_drop)]\n",
    "\n",
    "train_df['token'] = train_df['token'].astype('category').cat.codes\n",
    "object_cols = train_df[train_features].select_dtypes(include=object).columns\n",
    "train_df[object_cols] = train_df[object_cols].astype(float)\n",
    "\n",
    "nan_features = get_na_features(train_df, train_features)\n",
    "grouped_train = train_df.groupby(['token'])\n",
    "for k, v in nan_features.items():\n",
    "    for value in v:\n",
    "        train_df[value] = grouped_train[value].transform(lambda x: x.ffill().fillna(0.0))\n",
    "\n",
    "feature_cols = pd.DataFrame(train_features)\n",
    "dtype_df = pd.DataFrame(train_df[train_features].select_dtypes(exclude=[float]).columns)\n",
    "train_features = [x for x in train_features if x not in dtype_df.values]\n",
    "\n",
    "# params = {'num_columns': len(train_features_test),\n",
    "#           'num_labels': 3,\n",
    "#           'hidden_units': [96, 96, 896, 448, 448, 256],\n",
    "#           'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882,\n",
    "#                             0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],\n",
    "#           'ls': 0,\n",
    "#           'lr': 1e-3,\n",
    "#           }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 1) get rid of 0's\n",
    "# 2) get rid of [-np.inf, np.inf]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### model parameters\n",
    "param.layers = [500,350,200]\n",
    "param.dropout_rate = 0.35\n",
    "\n",
    "###training parameters\n",
    "param.bs = 8192\n",
    "param.lr = 0.002\n",
    "param.epochs = 30\n",
    "param.wd = 0.02"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "groups = pd.factorize(\n",
    "    train_df['open_time'].dt.day.astype(str) + '_' + train_df['open_time'].dt.month.astype(str) + '_' + train_df[\n",
    "        'open_time'].dt.year.astype(str))[0]\n",
    "\n",
    "cv = tscv.PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    group_gap=31,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_features_test = train_features\n",
    "train_df = normalize_float_columns(train_df, train_features_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_weights(weights):\n",
    "    weights_inv = 1/weights\n",
    "    final_weights = weights_inv / weights_inv.sum()\n",
    "    return final_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "### adding overall AuC as a metric\n",
    "### for early stopping I only look at resp and resp_sum because they start overfitting earlier\n",
    "use_weights = True\n",
    "metrics =  [tf.keras.metrics.CategoricalCrossentropy(name='loss'),\n",
    "            tf.keras.metrics.AUC(name='AUC')]\n",
    "            # tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "scores = []\n",
    "batch_size = 4096"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Train Date is from 2020-01-01 00:00:00 - 2020-05-12 23:59:00\n",
      "0 : Valid Date is from 2020-06-13 00:15:00 - 2020-11-18 23:59:00\n",
      "Shape of Xtrain is (383040, 147), Shape of yTrain is (383040,)\n",
      "Class 0: train: 0.5186638471177945\n",
      "Class 0: train: 0.23460996240601503\n",
      "Class 0: train: 0.2467261904761905\n",
      "14310/14310 [==============================] - 19s 1ms/step\n",
      "1 : Train Date is from 2020-01-01 00:00:00 - 2020-10-18 23:59:00\n",
      "1 : Valid Date is from 2020-11-19 00:15:00 - 2021-04-26 23:59:00\n",
      "Class 0: train: 0.6083856544901065\n",
      "Class 0: train: 0.19091514459665146\n",
      "Class 0: train: 0.200699200913242\n",
      "14310/14310 [==============================] - 17s 1ms/step\n",
      "2 : Train Date is from 2020-01-01 00:00:00 - 2021-03-26 23:59:00\n",
      "2 : Valid Date is from 2021-04-27 00:15:00 - 2021-10-02 23:59:00\n",
      "Class 0: train: 0.5450264843557526\n",
      "Class 0: train: 0.22070861049519586\n",
      "Class 0: train: 0.2342649051490515\n",
      "14310/14310 [==============================] - 23s 2ms/step\n",
      "3 : Train Date is from 2020-01-01 00:00:00 - 2021-09-01 23:59:00\n",
      "3 : Valid Date is from 2021-10-03 00:15:00 - 2022-03-10 23:59:00\n",
      "Class 0: train: 0.5176986566484517\n",
      "Class 0: train: 0.2353870673952641\n",
      "Class 0: train: 0.24691427595628415\n",
      "14310/14310 [==============================] - 18s 1ms/step\n",
      "4 : Train Date is from 2020-01-01 00:00:00 - 2022-02-07 23:59:00\n",
      "4 : Valid Date is from 2022-03-11 00:15:00 - 2022-08-16 07:11:00\n",
      "Class 0: train: 0.5189075819968213\n",
      "Class 0: train: 0.23636983456147956\n",
      "Class 0: train: 0.24472258344169917\n",
      "14247/14247 [==============================] - 18s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "batch_size = 512\n",
    "df_pred = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df['label'], groups)):\n",
    "      min_train, max_train = min(train_df['open_time'].iloc[train_idx]).to_pydatetime(), max(\n",
    "          train_df['open_time'].iloc[train_idx]).to_pydatetime()\n",
    "      min_valid, max_valid = min(train_df['open_time'].iloc[val_idx]).to_pydatetime(), max(\n",
    "          train_df['open_time'].iloc[val_idx]).to_pydatetime()\n",
    "\n",
    "      x_train, x_val = train_df[train_features_test].iloc[train_idx], train_df[train_features_test].iloc[\n",
    "          val_idx]\n",
    "\n",
    "      print(f'{fold} : Train Date is from {min_train} - {max_train}')\n",
    "      print(f'{fold} : Valid Date is from {min_valid} - {max_valid}')\n",
    "\n",
    "      y_train, y_val = train_df['label'].iloc[train_idx].values, train_df['label'].iloc[val_idx].values\n",
    "\n",
    "      if fold == 0:\n",
    "          print(f'Shape of Xtrain is {x_train.shape}, Shape of yTrain is {y_train.shape}')\n",
    "\n",
    "      if use_weights:\n",
    "        weights = []\n",
    "        for val in np.unique(y_train):\n",
    "            prop = (y_train == val).sum() / y_train.shape[0]\n",
    "            print(f'Class 0: train: {prop}')\n",
    "            weights.append(prop)\n",
    "        weights = np.array(weights)\n",
    "        loss_weights = get_weights(weights)\n",
    "        weights = {}\n",
    "        for i in range(len(loss_weights)):\n",
    "            weights[i] = loss_weights[i]\n",
    "\n",
    "        y_train = tf.one_hot(y_train, depth = 3)\n",
    "        y_val = tf.one_hot(y_val, depth = 3)\n",
    "\n",
    "      ckp_path = f'../output/MLP_{fold}.hdf5'\n",
    "      model = create_model(len(train_features_test), 3, param.layers, param.dropout_rate,\n",
    "                            optimizer=tfa.optimizers.Lookahead(\n",
    "                                tfa.optimizers.LAMB(learning_rate=param.lr, weight_decay_rate=param.wd)\n",
    "                            ),\n",
    "                            metrics=metrics)\n",
    "      model.load_weights(f'../output/MLP_{fold}.hdf5')\n",
    "\n",
    "      predictions = model.predict(x_val.values)\n",
    "      ypred = pd.DataFrame(predictions, columns = [f'prob_{i}' for i in range(3)])\n",
    "      cols_to_keep = ['open_time', 'label', 'target_15m', 'token', 'close', 'open']\n",
    "      x_df = train_df[cols_to_keep].iloc[val_idx].reset_index(drop = True)\n",
    "      x_df.columns = cols_to_keep\n",
    "      for i in range(3):\n",
    "          x_df[f'prob_{i}'] = ypred[f'prob_{i}']\n",
    "      df_pred.append(x_df)\n",
    "\n",
    "      # cbs = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "      #                                             patience=3, verbose=1),\n",
    "      #         tf.keras.callbacks.EarlyStopping(\n",
    "      #             monitor='val_AUC', patience=10, verbose=1,\n",
    "      #             mode='max', restore_best_weights=True, min_delta = 1e-4)\n",
    "      #         ]\n",
    "      #\n",
    "      # history = model.fit(x_train.values, y_train, validation_data=(x_val.values, y_val),\n",
    "      #                     epochs=param.epochs,\n",
    "      #                     batch_size=param.bs, callbacks=[ckp, cbs], class_weight = weights)\n",
    "      # hist = pd.DataFrame(history.history)\n",
    "      # hist.to_csv(f'../output/AEMLP_{fold}_training_history.csv')\n",
    "      # # hist.head(50)\n",
    "      # score = hist['val_AUC'].max()\n",
    "      # print(f'Fold {fold} ACC:\\t', score)\n",
    "      # scores.append(score)\n",
    "      # K.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_pred_test = pd.concat(df_pred, axis = 0)\n",
    "df_pred_test['pred_label'] = np.argmax(df_pred_test[[f'prob_0', 'prob_1', 'prob_2']].values, axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_pred_test['position'] = 0\n",
    "df_pred_test.loc[(df_pred_test['pred_label'] == 1), 'position'] = -1\n",
    "df_pred_test.loc[(df_pred_test['pred_label'] == 2), 'position'] = 1\n",
    "df_pred_test['return'] = df_pred_test['position'] * df_pred_test['target_15m']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_pred_test.reset_index(drop = True).to_feather('../data/back_test_output.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "df_pred_test['cum_ret'] = (1 + df_pred_test['return']).cumprod(axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "2119130"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test['cum_ret'].argmax()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_pred_test.plot(x = 0, y = 'cum_ret')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "params = {'num_columns': len(train_features_test),\n",
    "          'num_labels': 3,\n",
    "          'hidden_units': [96, 96, 896, 448, 448, 256],\n",
    "          'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882,\n",
    "                            0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],\n",
    "          'ls': 0,\n",
    "          'lr': 1e-3,\n",
    "          }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Train Date is from 2020-01-01 00:00:00 - 2020-05-12 23:59:00\n",
      "0 : Valid Date is from 2020-06-13 00:15:00 - 2020-11-18 23:59:00\n",
      "Shape of Xtrain is (383040, 142), Shape of yTrain is (383040,)\n",
      "Class 0: train: 0.5186664578111947\n",
      "Class 0: train: 0.23460996240601503\n",
      "Class 0: train: 0.2467235797827903\n",
      "14310/14310 [==============================] - 31s 2ms/step\n",
      "1 : Train Date is from 2020-01-01 00:00:00 - 2020-10-18 23:59:00\n",
      "1 : Valid Date is from 2020-11-19 00:15:00 - 2021-04-26 23:59:00\n",
      "Class 0: train: 0.6083868436073059\n",
      "Class 0: train: 0.19091395547945206\n",
      "Class 0: train: 0.200699200913242\n",
      "14310/14310 [==============================] - 30s 2ms/step\n",
      "2 : Train Date is from 2020-01-01 00:00:00 - 2021-03-26 23:59:00\n",
      "2 : Valid Date is from 2021-04-27 00:15:00 - 2021-10-02 23:59:00\n",
      "Class 0: train: 0.5450272542498152\n",
      "Class 0: train: 0.22070861049519586\n",
      "Class 0: train: 0.2342641352549889\n",
      "14310/14310 [==============================] - 29s 2ms/step\n",
      "3 : Train Date is from 2020-01-01 00:00:00 - 2021-09-01 23:59:00\n",
      "3 : Valid Date is from 2021-10-03 00:15:00 - 2022-03-10 23:59:00\n",
      "Class 0: train: 0.5176986566484517\n",
      "Class 0: train: 0.2353870673952641\n",
      "Class 0: train: 0.24691427595628415\n",
      "14310/14310 [==============================] - 30s 2ms/step\n",
      "4 : Train Date is from 2020-01-01 00:00:00 - 2022-02-07 23:59:00\n",
      "4 : Valid Date is from 2022-03-11 00:15:00 - 2022-08-16 07:11:00\n",
      "Class 0: train: 0.5189080335211674\n",
      "Class 0: train: 0.23636938303713337\n",
      "Class 0: train: 0.24472258344169917\n",
      "14247/14247 [==============================] - 29s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "batch_size = 4096\n",
    "df_pred = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df['label'], groups)):\n",
    "    min_train, max_train = min(train_df['open_time'].iloc[train_idx]).to_pydatetime(), max(\n",
    "          train_df['open_time'].iloc[train_idx]).to_pydatetime()\n",
    "    min_valid, max_valid = min(train_df['open_time'].iloc[val_idx]).to_pydatetime(), max(\n",
    "          train_df['open_time'].iloc[val_idx]).to_pydatetime()\n",
    "\n",
    "    x_train, x_val = train_df[train_features_test].iloc[train_idx], train_df[train_features_test].iloc[\n",
    "        val_idx]\n",
    "    y_train, y_val = train_df['label'].iloc[train_idx], train_df['label'].iloc[val_idx]\n",
    "\n",
    "\n",
    "    print(f'{fold} : Train Date is from {min_train} - {max_train}')\n",
    "    print(f'{fold} : Valid Date is from {min_valid} - {max_valid}')\n",
    "\n",
    "    y_train, y_val = train_df['label'].iloc[train_idx].values, train_df['label'].iloc[val_idx].values\n",
    "\n",
    "    if fold == 0:\n",
    "        print(f'Shape of Xtrain is {x_train.shape}, Shape of yTrain is {y_train.shape}')\n",
    "\n",
    "    if use_weights:\n",
    "        weights = []\n",
    "        for val in np.unique(y_train):\n",
    "            prop = (y_train == val).sum() / y_train.shape[0]\n",
    "            print(f'Class 0: train: {prop}')\n",
    "            weights.append(prop)\n",
    "        weights = np.array(weights)\n",
    "        loss_weights = get_weights(weights)\n",
    "        weights = {}\n",
    "        for i in range(len(loss_weights)):\n",
    "            weights[i] = loss_weights[i]\n",
    "\n",
    "        y_train = tf.one_hot(y_train, depth = 3)\n",
    "        y_val = tf.one_hot(y_val, depth = 3)\n",
    "\n",
    "    model = create_ae_mlp(**params)\n",
    "    model.load_weights(f'../output/AEMLP_{fold}_{batch_size}.hdf5')\n",
    "    predictions = model.predict(x_val.values)\n",
    "    ypred = pd.DataFrame(predictions[-1], columns = [f'prob_{i}' for i in range(3)])\n",
    "    cols_to_keep = ['open_time', 'label', 'target_15m', 'token']\n",
    "    tmp_df = pd.concat([train_df[cols_to_keep].iloc[val_idx].reset_index(drop = True), ypred], axis = 1, ignore_index = True)\n",
    "    df_pred.append(tmp_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "                         0  1         2  3         4         5         6\n0      2022-03-11 00:15:00  1 -0.005486  0  0.544133  0.220358  0.235509\n1      2022-03-11 00:16:00  1 -0.002619  0  0.603810  0.193890  0.202299\n2      2022-03-11 00:16:00  1 -0.003931  1  0.743910  0.134652  0.121438\n3      2022-03-11 00:17:00  0 -0.001781  1  0.725732  0.145121  0.129147\n4      2022-03-11 00:17:00  0 -0.001066  0  0.606421  0.192600  0.200979\n...                    ... ..       ... ..       ...       ...       ...\n455868 2022-08-16 07:09:00  0  0.000046  1  0.647001  0.169039  0.183960\n455869 2022-08-16 07:10:00  0 -0.001018  1  0.575753  0.183874  0.240373\n455870 2022-08-16 07:10:00  0 -0.000794  0  0.672766  0.145688  0.181546\n455871 2022-08-16 07:11:00  0 -0.001515  0  0.609655  0.180602  0.209743\n455872 2022-08-16 07:11:00  0 -0.000642  1  0.605853  0.172242  0.221905\n\n[455873 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-03-11 00:15:00</td>\n      <td>1</td>\n      <td>-0.005486</td>\n      <td>0</td>\n      <td>0.544133</td>\n      <td>0.220358</td>\n      <td>0.235509</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-03-11 00:16:00</td>\n      <td>1</td>\n      <td>-0.002619</td>\n      <td>0</td>\n      <td>0.603810</td>\n      <td>0.193890</td>\n      <td>0.202299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-03-11 00:16:00</td>\n      <td>1</td>\n      <td>-0.003931</td>\n      <td>1</td>\n      <td>0.743910</td>\n      <td>0.134652</td>\n      <td>0.121438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-03-11 00:17:00</td>\n      <td>0</td>\n      <td>-0.001781</td>\n      <td>1</td>\n      <td>0.725732</td>\n      <td>0.145121</td>\n      <td>0.129147</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-03-11 00:17:00</td>\n      <td>0</td>\n      <td>-0.001066</td>\n      <td>0</td>\n      <td>0.606421</td>\n      <td>0.192600</td>\n      <td>0.200979</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>455868</th>\n      <td>2022-08-16 07:09:00</td>\n      <td>0</td>\n      <td>0.000046</td>\n      <td>1</td>\n      <td>0.647001</td>\n      <td>0.169039</td>\n      <td>0.183960</td>\n    </tr>\n    <tr>\n      <th>455869</th>\n      <td>2022-08-16 07:10:00</td>\n      <td>0</td>\n      <td>-0.001018</td>\n      <td>1</td>\n      <td>0.575753</td>\n      <td>0.183874</td>\n      <td>0.240373</td>\n    </tr>\n    <tr>\n      <th>455870</th>\n      <td>2022-08-16 07:10:00</td>\n      <td>0</td>\n      <td>-0.000794</td>\n      <td>0</td>\n      <td>0.672766</td>\n      <td>0.145688</td>\n      <td>0.181546</td>\n    </tr>\n    <tr>\n      <th>455871</th>\n      <td>2022-08-16 07:11:00</td>\n      <td>0</td>\n      <td>-0.001515</td>\n      <td>0</td>\n      <td>0.609655</td>\n      <td>0.180602</td>\n      <td>0.209743</td>\n    </tr>\n    <tr>\n      <th>455872</th>\n      <td>2022-08-16 07:11:00</td>\n      <td>0</td>\n      <td>-0.000642</td>\n      <td>1</td>\n      <td>0.605853</td>\n      <td>0.172242</td>\n      <td>0.221905</td>\n    </tr>\n  </tbody>\n</table>\n<p>455873 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "df_pred_test = pd.concat(df_pred, axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "Index([0, 1, 2, 3, 4, 5, 6, 'pred_label'], dtype='object')"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "df_pred_test = pd.concat(df_pred, axis = 0)\n",
    "df_pred_test['pred_label'] = np.argmax(df_pred_test[[4, 5, 6]].values, axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "df_1 = df_pred_test.loc[(df_pred_test[1] == 1)]\n",
    "acc_1 = (df_1[1] == df_1['pred_label']).sum() / df_1.shape[0]\n",
    "df_2 = df_pred_test.loc[(df_pred_test[1] == 2)]\n",
    "acc_2 = (df_2[1] == df_2['pred_label']).sum() / df_2.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "0.11106521821471022"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}