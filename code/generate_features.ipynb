{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "from factor_util import *\n",
    "from joblib import dump, load\n",
    "from fredapi import Fred\n",
    "\n",
    "def hullMA(x, n = 50):\n",
    "    sma1 = x.rolling(n,  min_periods = 1).mean()\n",
    "    sma2 = x.rolling(int(n/2),  min_periods = 1).mean()\n",
    "    out = (2 * sma1 - sma2).rolling(int(np.sqrt(n)), min_periods = 1).mean()\n",
    "    return x - out\n",
    "\n",
    "def calculate_corr(df, ta_features = None, columns = None, groupby = True):\n",
    "    if ta_features is None:\n",
    "        skip_features = ['returns_5m', 'open_time', 'close_time', 'target_15m', 'ignore', 'token']\n",
    "        features = [x for x in df.columns if x not in skip_features]\n",
    "        ta_features = [x for x in df.columns if x not in skip_features and x not in columns]\n",
    "    if groupby:\n",
    "        tgt_corr = df.groupby(['token'])[ta_features + ['target_15m']].corr()\n",
    "    else:\n",
    "        tgt_corr = df[ta_features + ['target_15m']].corr()\n",
    "    return tgt_corr\n",
    "\n",
    "def calculate_vol_price_corr(df, windows = [5, 15, 30, 60, 120]):\n",
    "    for window in windows:\n",
    "        df[f'vol_price_corr_{window}'] = df['close'].rolling(window, min_periods = 1).corr(df['volume'])\n",
    "    return df\n",
    "\n",
    "def get_cols_for_corr(df, str_idx):\n",
    "    return df.columns[df.columns.str.startswith(str_idx)].tolist()\n",
    "\n",
    "def transform_time(df):\n",
    "    day = 24 * 60\n",
    "    hour_float = df['open_time'].dt.hour + df['open_time'].dt.minute/60\n",
    "    df['sin_hour'] = np.sin(2.0 * np.pi * hour_float/24)\n",
    "    df['cos_hour'] = np.cos(2.0 * np.pi * hour_float/24)\n",
    "    df['Day_sin'] = np.sin(df['open_time'].dt.day * (2 * np.pi / 31))\n",
    "    df['Day_cos'] = np.cos(df['open_time'].dt.day * (2 * np.pi / 31))\n",
    "    df['month_sin'] = np.sin(df['open_time'].dt.month * (2 * np.pi / 12))\n",
    "    df['month_cos'] = np.cos(df['open_time'].dt.month * (2 * np.pi / 12))\n",
    "    return df\n",
    "\n",
    "def calc_sma_diff_test(close, timeperiod_short, timeperiod_long):\n",
    "    res_short = close.rolling(window = timeperiod_short, min_periods = 1).mean()\n",
    "    res_long = close.rolling(window = timeperiod_long, min_periods = 1).mean()\n",
    "    res = (res_long - res_short) / res_long\n",
    "    return res\n",
    "\n",
    "def load_metrics_data(ticker):\n",
    "    df_metrics = pd.read_feather(f'../data/processed_metrics/{ticker}_1m.feather')\n",
    "    df_metrics['create_time'] = pd.to_datetime(df_metrics['create_time'], format = 'mixed')\n",
    "    return df_metrics\n",
    "\n",
    "def gen_cross_features(x, lag = 60):\n",
    "    \"\"\"\n",
    "    calculate cross features with other assets if any\n",
    "    :param x:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lag_arr = np.ones(lag)\n",
    "    conv_arr = np.convolve(x, lag_arr / lag, mode = 'valid')\n",
    "    app_arr = np.append(conv_arr, np.ones(lag - 1))\n",
    "    roll_arr = np.roll(app_arr, lag - 1)\n",
    "    div_arr = np.log(x / roll_arr)\n",
    "    return div_arr\n",
    "\n",
    "def log_return_np(x):\n",
    "    return np.log(x / x.shift(60)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "directory = '../data/processed_data/'\n",
    "files = pathlib.Path(directory).glob('*.feather')\n",
    "dfs = {}\n",
    "universe = ['BTCUSDT']\n",
    "\n",
    "df_btc = pd.read_feather('../data/processed_data/BTCUSDT_5m_spot.feather')\n",
    "df_btc = df_btc.sort_values(by = ['open_time'], ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "lag = 60\n",
    "df = df_btc.copy()\n",
    "df[f'log_close/mean_{lag}'] = gen_cross_features(df['close'], lag = lag)\n",
    "df[f'log_return_{lag}'] = log_return_np(df['close'])\n",
    "df['mid_diff'] = (df['close'] - df['open']) / ((df['high'] - df['low']) + 0.001)\n",
    "\n",
    "sma_lags = [5, 15, 30, 60, 120, 240, 800]\n",
    "for sma_lag in sma_lags:\n",
    "    df[f'sma{sma_lag}'] = (df['close'].rolling(sma_lag, min_periods = 1).mean())\n",
    "    df[f'sma{sma_lag}'] = (df[f'sma{sma_lag}'] / df['close']) - 1\n",
    "    df[f'return{sma_lag}'] = df['close'].pct_change(sma_lag)\n",
    "    df[f'volume_change_{sma_lag}'] = df['volume'].pct_change(sma_lag)\n",
    "\n",
    "hull_lags = [76, 240, 800]\n",
    "for hull_lag in hull_lags:\n",
    "    df[f'hull_{hull_lag}'] = hullMA(df['close'], hull_lag)\n",
    "\n",
    "fibo_list = [55, 210, 340, 890, 3750]\n",
    "for num in fibo_list:\n",
    "    df[f'log_return_{num}'] = np.log(df['close']).diff().rolling(num, min_periods = 1).mean().ffill().bfill()\n",
    "\n",
    "momentum_windows = [15, 30, 60, 120, 240]\n",
    "for window in momentum_windows:\n",
    "    df[f'mom_roc_{window}'] = df['close'].shift(-window)\n",
    "\n",
    "df = transform_time(df)\n",
    "sma_diff_windows = [(12 * np.power(4, i), 24 * np.power(4,i)) for i in range(1, 6)]\n",
    "for short_win, long_win in sma_diff_windows:\n",
    "    df[f'sma_diff_{short_win}'] = calc_sma_diff_test(df['close'], short_win, long_win)\n",
    "\n",
    "df[f'sma_diff_vol_{12*4*4}'] = calc_sma_diff_test(df['volume'], 12*4*4, 24*4*4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_intervals = [30, 60, 90, 120, 150, 180, 210, 240,\n",
    "                    270, 300, 330, 360, 390, 420, 450, 480]\n",
    "interval = 5\n",
    "corr = {}\n",
    "df = df.sort_values(by = ['open_time'], ignore_index = True)\n",
    "skip_features = ['returns_5m', 'open_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                 'close_time', 'target_15m', 'ignore', 'token',\n",
    "                 'taker_buy_base_volume', 'taker_buy_quote_asset_volume']\n",
    "\n",
    "features = [x for x in df.columns if (x not in skip_features)]\n",
    "features = [x for x in features if ('target' not in x)]\n",
    "\n",
    "\n",
    "for target_interval in target_intervals:\n",
    "    nperiod = target_interval // interval\n",
    "    label = f'target_{target_interval}m'\n",
    "    df[f'close_{nperiod}lag'] = df['close'].shift(nperiod).fillna(0.0)\n",
    "    df[f'target_{target_interval}m'] = df['close'].pct_change(-nperiod)\n",
    "    corr[label] = df[features + [label]].corr()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for k, v in corr.items():\n",
    "    v = v[k].abs().sort_values(ascending = False).iloc[1:]\n",
    "    v.to_csv(f'../output/feature_corr/{k}_feature.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df.to_feather('../data/df_btc_with_features_5m_spot.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "# from factor_util import *\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "# from factor_util import *\n",
    "from joblib import dump, load\n",
    "\n",
    "def hullMA(x, n = 50):\n",
    "    sma1 = x.rolling(n,  min_periods = 1).mean()\n",
    "    sma2 = x.rolling(int(n/2),  min_periods = 1).mean()\n",
    "    out = (2 * sma1 - sma2).rolling(int(np.sqrt(n)), min_periods = 1).mean()\n",
    "    return x - out\n",
    "\n",
    "def calculate_corr(df, ta_features = None, columns = None, groupby = True):\n",
    "    if ta_features is None:\n",
    "        skip_features = ['returns_5m', 'open_time', 'close_time', 'target_15m', 'ignore', 'token']\n",
    "        features = [x for x in df.columns if x not in skip_features]\n",
    "        ta_features = [x for x in df.columns if x not in skip_features and x not in columns]\n",
    "    if groupby:\n",
    "        tgt_corr = df.groupby(['token'])[ta_features + ['target_15m']].corr()\n",
    "    else:\n",
    "        tgt_corr = df[ta_features + ['target_15m']].corr()\n",
    "    return tgt_corr\n",
    "\n",
    "def calculate_vol_price_corr(df, windows = [5, 15, 30, 60, 120]):\n",
    "    for window in windows:\n",
    "        df[f'vol_price_corr_{window}'] = df['close'].rolling(window).corr(df['volume'])\n",
    "    return df\n",
    "\n",
    "def get_cols_for_corr(df, str_idx):\n",
    "    return df.columns[df.columns.str.startswith(str_idx)].tolist()\n",
    "\n",
    "def transform_time(df):\n",
    "    day = 24 * 60\n",
    "    hour_float = df['open_time'].dt.hour + df['open_time'].dt.minute/60\n",
    "    df['sin_hour'] = np.sin(2.0 * np.pi * hour_float/24)\n",
    "    df['cos_hour'] = np.cos(2.0 * np.pi * hour_float/24)\n",
    "    df['Day_sin'] = np.sin(df['open_time'].dt.day * (2 * np.pi / 31))\n",
    "    df['Day_cos'] = np.cos(df['open_time'].dt.day * (2 * np.pi / 31))\n",
    "    df['month_sin'] = np.sin(df['open_time'].dt.month * (2 * np.pi / 12))\n",
    "    df['month_cos'] = np.cos(df['open_time'].dt.month * (2 * np.pi / 12))\n",
    "    return df\n",
    "\n",
    "def calc_sma_diff_test(close, timeperiod_short, timeperiod_long):\n",
    "    res_short = close.rolling(window = timeperiod_short).mean()\n",
    "    res_long = close.rolling(window = timeperiod_long).mean()\n",
    "    res = (res_long - res_short) / res_long\n",
    "    return res\n",
    "\n",
    "def load_metrics_data(ticker):\n",
    "    df_metrics = pd.read_feather(f'../data/processed_metrics/{ticker}_1m.feather')\n",
    "    df_metrics['create_time'] = pd.to_datetime(df_metrics['create_time'], format = 'mixed')\n",
    "    return df_metrics\n",
    "\n",
    "def gen_cross_features(x, lag = 60):\n",
    "    \"\"\"\n",
    "    calculate cross features with other assets if any\n",
    "    :param x:\n",
    "    :param lag:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lag_arr = np.ones(lag)\n",
    "    conv_arr = np.convolve(x, lag_arr / lag, mode = 'valid')\n",
    "    app_arr = np.append(conv_arr, np.ones(lag - 1))\n",
    "    roll_arr = np.roll(app_arr, lag - 1)\n",
    "    div_arr = np.log(x / roll_arr)\n",
    "    return div_arr\n",
    "\n",
    "def log_return_np(x):\n",
    "    return np.log(x / x.shift(60)).fillna(0)\n",
    "\n",
    "def generate_features(df):\n",
    "    directory = '../data/processed_data/'\n",
    "\n",
    "    # df = pd.concat([df_btc, df_eth], axis = 0, ignore_index = True)\n",
    "    df = df.sort_values(by = ['open_time'], ignore_index = True)\n",
    "    # calculate next 15min returns (ie: current open_time is 2020-01-01 00:00:00,\n",
    "    # then return is from 2020-01-01 00:01:00 - 2020-01-01 00:16:00\n",
    "\n",
    "    sma_lags = [5, 10, 15, 30, 60, 90, 120, 150, 180, 210, 240,\n",
    "                270, 300, 330, 360, 390, 420, 450, 480, 510, 540, 570, 600, 660, 720]\n",
    "    for lag in sma_lags:\n",
    "        df[f'log_close/mean_{lag}'] = gen_cross_features(df['close'], lag=lag)\n",
    "        df[f'log_return_{lag}'] = log_return_np(df['close'])\n",
    "\n",
    "    df['mid_diff'] = (df['close'] - df['open']) / ((df['high'] - df['low']) + 0.001)\n",
    "\n",
    "\n",
    "\n",
    "    sma_lags = [5, 10, 15, 30, 60, 90, 120, 150, 180, 210, 240,\n",
    "                270, 300, 330, 360, 390, 420, 450, 480, 510, 540, 570, 600, 660, 720]\n",
    "    for sma_lag in sma_lags:\n",
    "        df[f'sma{sma_lag}'] = (df['close'].rolling(sma_lag).mean())\n",
    "        df[f'sma{sma_lag}'] = (df[f'sma{sma_lag}'] / df['close']) - 1\n",
    "        df[f'return{sma_lag}'] = df['close'].pct_change(sma_lag)\n",
    "        df[f'volume_change_{sma_lag}'] = df['volume'].pct_change(sma_lag)\n",
    "\n",
    "    hull_lags = [15, 30, 60, 90, 120, 150, 180, 210, 240,\n",
    "                270, 300, 330, 360, 390, 420, 450, 480, 510, 540, 570, 600, 660, 720]\n",
    "    for hull_lag in hull_lags:\n",
    "        df[f'hull_{hull_lag}'] = hullMA(df['close'], hull_lag)\n",
    "\n",
    "    fibo_list = [15, 30, 60, 90, 120, 150, 180, 210, 240,\n",
    "                270, 300, 330, 360, 390, 420, 450, 480, 510, 540, 570, 600, 660, 720]\n",
    "    for num in fibo_list:\n",
    "        df[f'log_return_{num}'] = np.log(df['close']).diff().rolling(num).mean().ffill().bfill()\n",
    "\n",
    "\n",
    "    # momentum_windows = [15, 30, 60, 90, 120, 150, 180, 210, 240,\n",
    "    #                     270, 300, 330, 360, 390, 420, 450, 480,\n",
    "    #                     510, 540, 570, 600, 660, 720]\n",
    "    # for window in momentum_windows:\n",
    "    #     df[f'mom_roc_{window}'] = df['close'].pct_change(window)\n",
    "\n",
    "    # momentum_windows = [15, 30, 60, 120, 240]\n",
    "    # for window in momentum_windows:\n",
    "    #     df_btc[f'mom_adx_{window}'] = talib.ADX(df_btc['high'], df_btc['low'], df_btc['close'], timeperiod = window)\n",
    "    #     df_btc[f'mom_adxr_{window}'] = talib.ADXR(df_btc['high'], df_btc['low'], df_btc['close'], timeperiod=window)\n",
    "\n",
    "    df = transform_time(df)\n",
    "    sma_diff_windows = [(12 * np.power(4, i), 24 * np.power(4, i)) for i in range(1, 10)]\n",
    "    for short_win, long_win in sma_diff_windows:\n",
    "        df[f'sma_diff_{short_win}'] = calc_sma_diff_test(df['close'], int(short_win), int(long_win))\n",
    "\n",
    "    df[f'sma_diff_vol_{12 * 4 * 4}'] = calc_sma_diff_test(df['volume'], 12 * 4 * 4, 24 * 4 * 4)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Features using more lags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/df_btc_with_features_5m_spot.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "VOL_THRESHOLD = 5  # multiple to winsorise by\n",
    "HALFLIFE_WINSORISE = 252\n",
    "\n",
    "df_asset = df.copy()\n",
    "df_asset = df_asset[\n",
    "    ~df_asset[\"close\"].isna()\n",
    "    | ~df_asset[\"close\"].isnull()\n",
    "    | (df_asset[\"close\"] > 1e-8)  # price is zero\n",
    "].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calc_returns(srs: pd.Series, day_offset: int = 1) -> pd.Series:\n",
    "    returns = srs / srs.shift(day_offset) - 1.0\n",
    "    return returns\n",
    "\n",
    "VOL_LOOKBACK = 60  # for ex-ante volatility\n",
    "VOL_TARGET = 0.15  # 15% volatility target\n",
    "\n",
    "def calc_daily_vol(daily_returns):\n",
    "    return (\n",
    "        daily_returns.ewm(span=VOL_LOOKBACK, min_periods=VOL_LOOKBACK)\n",
    "        .std()\n",
    "        .fillna(method=\"bfill\")\n",
    "    )\n",
    "\n",
    "def calc_normalised_returns(day_offset):\n",
    "    return (\n",
    "        calc_returns(df_asset[\"srs\"], day_offset)\n",
    "        / df_asset[\"vol_5m\"]\n",
    "        / np.sqrt(day_offset)\n",
    "    )\n",
    "\n",
    "def calc_macd_signal(srs: pd.Series, short_timescale: int, long_timescale: int) -> float:\n",
    "    def _calc_halflife(timescale):\n",
    "        return np.log(0.5) / np.log(1 - 1 / timescale)\n",
    "\n",
    "    macd = (\n",
    "        srs.ewm(halflife=_calc_halflife(short_timescale)).mean()\n",
    "        - srs.ewm(halflife=_calc_halflife(long_timescale)).mean()\n",
    "    )\n",
    "    q = macd / srs.rolling(63).std().fillna(method=\"bfill\")\n",
    "    return q / q.rolling(252).std().fillna(method=\"bfill\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# winsorize using rolling 5X standard deviations to remove outliers\n",
    "df_asset[\"srs\"] = df_asset[\"close\"]\n",
    "ewm = df_asset[\"srs\"].ewm(halflife=HALFLIFE_WINSORISE)\n",
    "means = ewm.mean()\n",
    "stds = ewm.std()\n",
    "df_asset[\"srs\"] = np.minimum(df_asset[\"srs\"], means + VOL_THRESHOLD * stds)\n",
    "df_asset[\"srs\"] = np.maximum(df_asset[\"srs\"], means - VOL_THRESHOLD * stds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_68096/3358842547.py:10: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  daily_returns.ewm(span=VOL_LOOKBACK, min_periods=VOL_LOOKBACK)\n",
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_68096/3358842547.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  q = macd / srs.rolling(63).std().fillna(method=\"bfill\")\n",
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_68096/3358842547.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  return q / q.rolling(252).std().fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "df_asset[\"returns_5m\"] = calc_returns(df_asset[\"srs\"])\n",
    "df_asset[\"vol_5m\"] = calc_daily_vol(df_asset[\"returns_5m\"])\n",
    "\n",
    "\n",
    "times = [(2, '10m'), (3, '15m'), (6, '30m'), (12, '60m'), (24, '120m'),\n",
    "         (48, '240m'), (96, '480m'), (192, '720m')]\n",
    "\n",
    "for x, y in times:\n",
    "    df_asset[f\"norm_return_{y}\"] = calc_normalised_returns(x)\n",
    "\n",
    "trend_combinations = [(8, 24), (16, 48), (32, 96)]\n",
    "for short_window, long_window in trend_combinations:\n",
    "    df_asset[f\"macd_{short_window}_{long_window}\"] = calc_macd_signal(\n",
    "        df_asset[\"srs\"], short_window, long_window\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 01:05:25.923683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mom_trans.changepoint_detection as cpd\n",
    "#\n",
    "# cpd.run_module(\n",
    "#     data, lookback_window_length, output_file_path, start_date, end_date, USE_KM_HYP_TO_INITIALISE_KC\n",
    "# ) , (12, '60m'), (24, '120m'), (48, '240m')\n",
    "cpd_time = [(6, '30m')]\n",
    "df_asset.index = df_asset['open_time']\n",
    "df_asset['daily_returns'] = df_asset['returns_5m'].copy()\n",
    "\n",
    "output = cpd.run_module(df_asset, 6, output_csv_file_path = '../data/sample')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}