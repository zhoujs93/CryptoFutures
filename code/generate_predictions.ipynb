{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "List of Ideas:\n",
    "- See bookmarks:\n",
    "- Automating Feature Engineering (Part II)\n",
    "- Use LightGBM for feature importance (Crypto Forecasting - lgbm feval+feature importance)\n",
    "- Crypto Forecasting - Common Factors\n",
    "- Correlation as loss function ? https://www.kaggle.com/competitions/open-problems-multimodal/discussion/347595#1916337\n",
    "-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.python.keras.backend as K\n",
    "import tensorflow.python.keras.layers as layers\n",
    "from tensorflow.python.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls=1e-2, lr=1e-3):\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x0 = tf.keras.layers.BatchNormalization()(inp)\n",
    "\n",
    "    encoder = tf.keras.layers.GaussianNoise(dropout_rates[0])(x0)\n",
    "    encoder = tf.keras.layers.Dense(hidden_units[0])(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Activation('swish')(encoder)\n",
    "\n",
    "    decoder = tf.keras.layers.Dropout(dropout_rates[1])(encoder)\n",
    "    decoder = tf.keras.layers.Dense(num_columns, name='decoder')(decoder)\n",
    "\n",
    "    x_ae = tf.keras.layers.Dense(hidden_units[1])(decoder)\n",
    "    x_ae = tf.keras.layers.BatchNormalization()(x_ae)\n",
    "    x_ae = tf.keras.layers.Activation('swish')(x_ae)\n",
    "    x_ae = tf.keras.layers.Dropout(dropout_rates[2])(x_ae)\n",
    "\n",
    "    out_ae = tf.keras.layers.Dense(num_labels, activation='sigmoid', name='ae_action')(x_ae)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x0, encoder])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[3])(x)\n",
    "\n",
    "    for i in range(2, len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('swish')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 2])(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(num_labels, activation='softmax', name='action')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=[decoder, out_ae, out])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss={'decoder': tf.keras.losses.MeanSquaredError(),\n",
    "                        'ae_action': tf.keras.losses.CategoricalCrossentropy(),\n",
    "                        'action': tf.keras.losses.CategoricalCrossentropy(),\n",
    "                        },\n",
    "                  metrics={'decoder': tf.keras.metrics.MeanAbsoluteError(name='MAE'),\n",
    "                           'ae_action': tf.keras.metrics.AUC(name='AUC'),\n",
    "                           'action': tf.keras.metrics.AUC(name='AUC'),\n",
    "                           },\n",
    "                  )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "def create_model(n_in, n_out, layers, dropout_rate, optimizer, metrics):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (n_in, ))\n",
    "\n",
    "    x=inp\n",
    "    for i,hidden_units in enumerate(layers):\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        if i>0:\n",
    "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "        else:\n",
    "            x = tf.keras.layers.Dropout(.01)(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units)(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(n_out, activation = 'softmax', name = 'action')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics = metrics,\n",
    "#                   run_eagerly=True\n",
    "                 )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import tscv\n",
    "\n",
    "def generate_label(df, threshold = 0.002):\n",
    "    df['label'] = 0\n",
    "    df.loc[(df['target_15m'] <= -1*threshold), 'label'] = 1\n",
    "    df.loc[(df['target_15m'] >= threshold), 'label'] = 2\n",
    "    return df\n",
    "\n",
    "def get_na_features(df, train_features):\n",
    "    tmp = pd.DataFrame(df[train_features].isnull().sum())\n",
    "    tmp = tmp[tmp[0] > 0].reset_index()\n",
    "    tmp.columns = ['feat', 'cnt']\n",
    "    tmp = tmp.sort_values('cnt')\n",
    "    feat_groups = dict(tmp.groupby('cnt')['feat'].agg(lambda x: list(x)))\n",
    "    return feat_groups\n",
    "\n",
    "def normalize_float_columns(df, features):\n",
    "  float_cols = df[features].select_dtypes(include = [float]).columns\n",
    "  grouped_df = df.groupby(['token'])\n",
    "  for col in float_cols:\n",
    "      df[col] = grouped_df[col].transform(lambda x: (x - x.mean()) / (x.std()))\n",
    "  df[float_cols] = (df[float_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0))\n",
    "  return df\n",
    "\n",
    "class Params: pass\n",
    "param = Params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/df_btc_eth_with_features.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cols = pd.DataFrame(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                    0\n0           open_time\n1                open\n2                high\n3                 low\n4               close\n..                ...\n155       sma_diff_12\n156      sma_diff_192\n157      sma_diff_768\n158     sma_diff_3072\n159  sma_diff_vol_192\n\n[160 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>open_time</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>high</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>close</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>sma_diff_12</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>sma_diff_192</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>sma_diff_768</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>sma_diff_3072</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>sma_diff_vol_192</td>\n    </tr>\n  </tbody>\n</table>\n<p>160 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train = False\n",
    "df = pd.read_feather('../data/df_btc_eth_with_features.feather')\n",
    "cols_to_drop = ['open_time', 'close_time', 'ignore',\n",
    "                'create_time', 'symbol', 'returns', 'returns_5m',\n",
    "                'open', 'hi gh', 'low', 'close', 'target_15m', 'label']\n",
    "\n",
    "df = df.sort_values(by='open_time', ignore_index=True)\n",
    "df = generate_label(df, threshold=0.002)\n",
    "\n",
    "start_time = df['open_time'].min()\n",
    "end_time = df['open_time'].max()\n",
    "dates = df['open_time'].unique()\n",
    "n = len(dates)\n",
    "train_idx = int(0.7 * n)\n",
    "valid_idx = int(0.9 * n)\n",
    "train_end = dates[train_idx]\n",
    "valid_end = dates[valid_idx]\n",
    "\n",
    "train_df = df.loc[df['open_time'] < train_end].reset_index(drop=True)\n",
    "valid_df = df.loc[(train_end <= df['open_time']) & (df['open_time'] < valid_end)].reset_index(drop=True)\n",
    "test_df = df.loc[(df['open_time'] >= valid_end)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "train_features = [x for x in df.columns if (x not in cols_to_drop)]\n",
    "\n",
    "valid_df['token'] = valid_df['token'].astype('category').cat.codes\n",
    "object_cols = valid_df[train_features].select_dtypes(include=object).columns\n",
    "valid_df[object_cols] = valid_df[object_cols].astype(float)\n",
    "\n",
    "nan_features = get_na_features(valid_df, train_features)\n",
    "grouped_train = valid_df.groupby(['token'])\n",
    "for k, v in nan_features.items():\n",
    "    for value in v:\n",
    "        valid_df[value] = grouped_train[value].transform(lambda x: x.ffill().fillna(0.0))\n",
    "\n",
    "feature_cols = pd.DataFrame(train_features)\n",
    "dtype_df = pd.DataFrame(valid_df[train_features].select_dtypes(exclude=[float]).columns)\n",
    "train_features = [x for x in train_features if x not in dtype_df.values]\n",
    "\n",
    "# params = {'num_columns': len(train_features_test),\n",
    "#           'num_labels': 3,\n",
    "#           'hidden_units': [96, 96, 896, 448, 448, 256],\n",
    "#           'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882,\n",
    "#                             0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],\n",
    "#           'ls': 0,\n",
    "#           'lr': 1e-3,\n",
    "#           }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 1) get rid of 0's\n",
    "# 2) get rid of [-np.inf, np.inf]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "### model parameters\n",
    "param.layers = [500,350,200]\n",
    "param.dropout_rate = 0.35\n",
    "\n",
    "###training parameters\n",
    "param.bs = 8192\n",
    "param.lr = 0.002\n",
    "param.epochs = 30\n",
    "param.wd = 0.02"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "groups = pd.factorize(\n",
    "    train_df['open_time'].dt.day.astype(str) + '_' + train_df['open_time'].dt.month.astype(str) + '_' + train_df[\n",
    "        'open_time'].dt.year.astype(str))[0]\n",
    "\n",
    "cv = tscv.PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    group_gap=31,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "train_features_test = train_features\n",
    "valid_df = normalize_float_columns(valid_df, train_features_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def get_weights(weights):\n",
    "    weights_inv = 1/weights\n",
    "    final_weights = weights_inv / weights_inv.sum()\n",
    "    return final_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "### adding overall AuC as a metric\n",
    "### for early stopping I only look at resp and resp_sum because they start overfitting earlier\n",
    "use_weights = True\n",
    "metrics =  [tf.keras.metrics.CategoricalCrossentropy(name='loss'),\n",
    "            tf.keras.metrics.AUC(name='AUC')]\n",
    "            # tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "scores = []\n",
    "batch_size = 4096"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Date is from 2022-08-16 07:12:00 - 2023-05-17 02:23:00\n",
      "Valid Date is from 2022-08-16 07:12:00 - 2023-05-17 02:23:00\n",
      "Shape of Xtrain is (788544, 147), Shape of yTrain is (788544,)\n",
      "Class 0: train: 0.7189617827286746\n",
      "Class 0: train: 0.138683446960474\n",
      "Class 0: train: 0.1423547703108514\n",
      "24642/24642 [==============================] - 31s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "batch_size = 512\n",
    "df_pred = []\n",
    "min_train, max_train = min(valid_df['open_time']).to_pydatetime(), max(\n",
    "  valid_df['open_time']).to_pydatetime()\n",
    "\n",
    "x_train, x_val = valid_df[train_features_test], valid_df[train_features_test]\n",
    "\n",
    "print(f'Train Date is from {min_train} - {max_train}')\n",
    "print(f'Valid Date is from {min_valid} - {max_valid}')\n",
    "\n",
    "y_train, y_val = valid_df['label'].values, valid_df['label'].values\n",
    "\n",
    "print(f'Shape of Xtrain is {x_train.shape}, Shape of yTrain is {y_train.shape}')\n",
    "\n",
    "if use_weights:\n",
    "    weights = []\n",
    "    for val in np.unique(y_train):\n",
    "        prop = (y_train == val).sum() / y_train.shape[0]\n",
    "        print(f'Class 0: train: {prop}')\n",
    "        weights.append(prop)\n",
    "    weights = np.array(weights)\n",
    "    loss_weights = get_weights(weights)\n",
    "    weights = {}\n",
    "    for i in range(len(loss_weights)):\n",
    "        weights[i] = loss_weights[i]\n",
    "\n",
    "y_train = tf.one_hot(y_train, depth = 3)\n",
    "y_val = tf.one_hot(y_val, depth = 3)\n",
    "\n",
    "ckp_path = f'../output/MLP_4.hdf5'\n",
    "model = create_model(len(train_features_test), 3, param.layers, param.dropout_rate,\n",
    "                    optimizer=tfa.optimizers.Lookahead(\n",
    "                        tfa.optimizers.LAMB(learning_rate=param.lr, weight_decay_rate=param.wd)\n",
    "                    ),\n",
    "                    metrics=metrics)\n",
    "model.load_weights(f'../output/MLP_4.hdf5')\n",
    "\n",
    "predictions = model.predict(x_val.values)\n",
    "ypred = pd.DataFrame(predictions, columns = [f'prob_{i}' for i in range(3)])\n",
    "cols_to_keep = ['open_time', 'label', 'target_15m', 'token', 'close', 'open']\n",
    "x_df = valid_df[cols_to_keep].reset_index(drop = True)\n",
    "x_df.columns = cols_to_keep\n",
    "for i in range(3):\n",
    "  x_df[f'prob_{i}'] = ypred[f'prob_{i}']\n",
    "df_pred.append(x_df)\n",
    "\n",
    "# cbs = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "#                                             patience=3, verbose=1),\n",
    "#         tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_AUC', patience=10, verbose=1,\n",
    "#             mode='max', restore_best_weights=True, min_delta = 1e-4)\n",
    "#         ]\n",
    "#\n",
    "# history = model.fit(x_train.values, y_train, validation_data=(x_val.values, y_val),\n",
    "#                     epochs=param.epochs,\n",
    "#                     batch_size=param.bs, callbacks=[ckp, cbs], class_weight = weights)\n",
    "# hist = pd.DataFrame(history.history)\n",
    "# hist.to_csv(f'../output/AEMLP_{fold}_training_history.csv')\n",
    "# # hist.head(50)\n",
    "# score = hist['val_AUC'].max()\n",
    "# print(f'Fold {fold} ACC:\\t', score)\n",
    "# scores.append(score)\n",
    "# K.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "df_pred_test = pd.concat(df_pred, axis = 0)\n",
    "prob_cols = [f'prob_{i}' for i in range(3)]\n",
    "df_pred_test['pred_label'] = np.argmax(df_pred_test[prob_cols].values, axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "df_pred_test.to_feather('../data/back_test_output_valid.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "### model parameters\n",
    "param.layers = [500,350,200]\n",
    "param.dropout_rate = 0.35\n",
    "\n",
    "###training parameters\n",
    "param.bs = 8192\n",
    "param.lr = 0.002\n",
    "param.epochs = 30\n",
    "param.wd = 0.02"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "groups = pd.factorize(\n",
    "    valid_df['open_time'].dt.day.astype(str) + '_' + valid_df['open_time'].dt.month.astype(str) + '_' + valid_df[\n",
    "        'open_time'].dt.year.astype(str))[0]\n",
    "\n",
    "cv = tscv.PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    group_gap=31,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_features_test = train_features\n",
    "valid_df = normalize_float_columns(valid_df, train_features_test)\n",
    "\n",
    "def get_weights(weights):\n",
    "    weights_inv = 1/weights\n",
    "    final_weights = weights_inv / weights_inv.sum()\n",
    "    return final_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "### adding overall AuC as a metric\n",
    "### for early stopping I only look at resp and resp_sum because they start overfitting earlier\n",
    "use_weights = True\n",
    "metrics =  [tf.keras.metrics.CategoricalCrossentropy(name='loss'),\n",
    "            tf.keras.metrics.AUC(name='AUC')]\n",
    "            # tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "scores = []\n",
    "batch_size = 4096"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "params = {'num_columns': len(train_features_test),\n",
    "          'num_labels': 3,\n",
    "          'hidden_units': [96, 96, 896, 448, 448, 256],\n",
    "          'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882,\n",
    "                            0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],\n",
    "          'ls': 0,\n",
    "          'lr': 1e-3,\n",
    "          }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Date is from 2022-08-16 07:12:00 - 2023-05-17 02:23:00\n",
      "Valid Date is from 2022-08-16 07:12:00 - 2023-05-17 02:23:00\n",
      "Shape of Xtrain is (788544, 147), Shape of yTrain is (788544,)\n",
      "Class 0: train: 0.7189617827286746\n",
      "Class 0: train: 0.138683446960474\n",
      "Class 0: train: 0.1423547703108514\n",
      "24642/24642 [==============================] - 63s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "batch_size = 4096\n",
    "df_pred = []\n",
    "\n",
    "min_train, max_train = min(valid_df['open_time']).to_pydatetime(), max(valid_df['open_time']).to_pydatetime()\n",
    "min_valid, max_valid = min(valid_df['open_time']).to_pydatetime(), max(\n",
    "              valid_df['open_time']).to_pydatetime()\n",
    "\n",
    "x_train, x_val = valid_df[train_features_test], valid_df[train_features_test]\n",
    "y_train, y_val = valid_df['label'], valid_df['label']\n",
    "\n",
    "\n",
    "print(f'Train Date is from {min_train} - {max_train}')\n",
    "print(f'Valid Date is from {min_valid} - {max_valid}')\n",
    "\n",
    "y_train, y_val = valid_df['label'], valid_df['label']\n",
    "print(f'Shape of Xtrain is {x_train.shape}, Shape of yTrain is {y_train.shape}')\n",
    "\n",
    "if use_weights:\n",
    "    weights = []\n",
    "    for val in np.unique(y_train):\n",
    "        prop = (y_train == val).sum() / y_train.shape[0]\n",
    "        print(f'Class 0: train: {prop}')\n",
    "        weights.append(prop)\n",
    "    weights = np.array(weights)\n",
    "    loss_weights = get_weights(weights)\n",
    "    weights = {}\n",
    "    for i in range(len(loss_weights)):\n",
    "        weights[i] = loss_weights[i]\n",
    "\n",
    "    y_train = tf.one_hot(y_train, depth = 3)\n",
    "    y_val = tf.one_hot(y_val, depth = 3)\n",
    "\n",
    "model = create_ae_mlp(**params)\n",
    "model.load_weights(f'../output/AEMLP_4_{batch_size}.hdf5')\n",
    "\n",
    "predictions = model.predict(x_val.values)\n",
    "preds = predictions[-1]\n",
    "ypred = pd.DataFrame(preds, columns = [f'prob_{i}' for i in range(3)])\n",
    "cols_to_keep = ['open_time', 'label', 'target_15m', 'token', 'close', 'open']\n",
    "x_df = valid_df[cols_to_keep].reset_index(drop = True)\n",
    "x_df.columns = cols_to_keep\n",
    "for i in range(3):\n",
    "  x_df[f'prob_{i}'] = ypred[f'prob_{i}']\n",
    "\n",
    "df_pred.append(x_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "df_pred_test = pd.concat(df_pred, axis = 0)\n",
    "prob_cols = [f'prob_{i}' for i in range(3)]\n",
    "df_pred_test['pred_label'] = np.argmax(df_pred_test[prob_cols].values, axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "df_pred_test.to_feather('../data/back_test_output_valid_aemlp.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}