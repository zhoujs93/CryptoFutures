{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
      "Requirement already satisfied: keras-beats in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
      "Requirement already satisfied: sktime in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (23.1)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from keras-beats) (2.14.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-beats) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scikit-base<0.7.0 in /usr/local/lib/python3.11/dist-packages (from sktime) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (68.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->keras-beats) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->keras-beats) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (4.9)\n",
      "Requirement already satisfied: urllib3>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (2.0.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->keras-beats) (3.2.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: ray[data,serve,train,tune] in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (8.1.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (4.19.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (23.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (4.24.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (14.0.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (2023.12.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (2.6.2.2)\n",
      "Requirement already satisfied: aiorwlock in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.3.0)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (6.4.0)\n",
      "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (20.21.0)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.104.1)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.3.14)\n",
      "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.7.0)\n",
      "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.24.0.post1)\n",
      "Requirement already satisfied: colorful in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.5.5)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.1.1)\n",
      "Requirement already satisfied: opencensus in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.11.3)\n",
      "Requirement already satisfied: starlette in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.27.0)\n",
      "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.10.13)\n",
      "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.21.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (0.17.1)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (3.9.1)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[data,serve,train,tune]) (1.58.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (1.9.3)\n",
      "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.11/dist-packages (from gpustat>=1.0.0->ray[data,serve,train,tune]) (12.535.133)\n",
      "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from gpustat>=1.0.0->ray[data,serve,train,tune]) (5.9.5)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.11/dist-packages (from gpustat>=1.0.0->ray[data,serve,train,tune]) (1.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->ray[data,serve,train,tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->ray[data,serve,train,tune]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->ray[data,serve,train,tune]) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2->ray[data,serve,train,tune]) (4.8.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray[data,serve,train,tune]) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.11/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray[data,serve,train,tune]) (3.10.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from fastapi->ray[data,serve,train,tune]) (3.7.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[data,serve,train,tune]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[data,serve,train,tune]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[data,serve,train,tune]) (0.10.3)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[data,serve,train,tune]) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[data,serve,train,tune]) (2.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[data,serve,train,tune]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[data,serve,train,tune]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[data,serve,train,tune]) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[data,serve,train,tune]) (2023.7.22)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (12.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->ray[data,serve,train,tune]) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[data,serve,train,tune]) (0.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[data,serve,train,tune]) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (1.61.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (2.23.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.5.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons keras-beats pandas scikit-learn sktime joblib\n",
    "!pip install -U \"ray[data,train,tune,serve]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from pyarrow) (1.26.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from kerasbeats import prep_time_series, NBeatsModel\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/df_btc_with_features_5m_spot.feather')\n",
    "\n",
    "df['target'] = df['close'].copy()\n",
    "\n",
    "start_time = df['open_time'].min()\n",
    "end_time = df['open_time'].max()\n",
    "dates = df['open_time'].unique()\n",
    "n = len(dates)\n",
    "train_idx = int(0.7 * n)\n",
    "test_idx = int(0.8 * n)\n",
    "\n",
    "train_df = df.iloc[:train_idx]\n",
    "valid_df = df.iloc[train_idx:test_idx]\n",
    "test_df = df.iloc[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.python.keras.backend as K\n",
    "import tensorflow.python.keras.layers as layers\n",
    "from tensorflow.python.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def create_nbeat_mlp(num_columns, num_labels, lookback, horizon, hidden_units, dropout_rates, ls=1e-2, lr=1e-3):\n",
    "    nbeats = NBeatsModel(model_type = 'generic', lookback = lookback, horizon = horizon,\n",
    "                         learning_rate = lr, batch_size = 4096,\n",
    "                         num_generic_neurons = hidden_units[0]) # set as default\n",
    "    nbeats.build_layer()\n",
    "    time_input = keras.layers.Input(shape = (lookback * horizon, ))\n",
    "    x_nb = nbeats.model_layer(time_input)\n",
    "\n",
    "    xcons = keras.layers.Input(shape = (num_columns, ))\n",
    "    x = keras.layers.Concatenate()([xcons, x_nb])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "\n",
    "    for i in range(1, len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('swish')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i])(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(num_labels, name = 'action')(x)\n",
    "    model = tf.keras.models.Model(inputs = [time_input, xcons], outputs = out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss = {'action' : tf.keras.losses.MeanSquaredError()},\n",
    "                  metrics = {'action' : tf.metrics.MeanSquaredError(name = 'mse')})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.python.keras.backend as K\n",
    "import tensorflow.python.keras.layers as layers\n",
    "from tensorflow.python.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from ray import train\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "from ray.data import read_numpy\n",
    "from ray.train.tensorflow.keras import ReportCheckpointCallback\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    batch_size = config.get('batch_size', 1024)\n",
    "    num_generic_neurons = config['num_generic_neurons']\n",
    "    num_generic_stacks = config['num_generic_stacks']\n",
    "    num_generic_layers = config['num_generic_layers']\n",
    "    num_trend_neurons = config['num_trend_neurons']\n",
    "    num_trend_stacks = config['num_trend_stacks']\n",
    "    num_trend_layers = config['num_trend_layers']\n",
    "    num_seasonal_neurons = config['num_seasonal_neurons']\n",
    "    polynomial_term = config['polynomial_term']\n",
    "    lr = config['learning_rate']\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = NBeatsModel(**config)\n",
    "        model.build_layer()\n",
    "        model.build_model()\n",
    "        ckp = ModelCheckpoint(ckp_path, monitor='r2score', verbose=0,\n",
    "                            save_best_only=True, save_weights_only=True, mode='max')\n",
    "        es = EarlyStopping(monitor='r2score', min_delta=1e-4, patience=10, mode='max',\n",
    "                            baseline=None, restore_best_weights=True, verbose=0)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss = [tf.keras.losses.MeanSquaredError(name = 'mse')],\n",
    "                      metrics = [tf.keras.metrics.MeanSquaredError(name = 'mse')])\n",
    "\n",
    "    x_tr, y_tr = read_numpy(f'../data/x_tr_{lookback}.npy'), read_numpy(f'../data/y_tr_{lookback}.npy')\n",
    "    x_val, y_val = read_numpy(f'../data/x_val_{lookback}.npy'),read_numpy(f'../data/y_val_{lookback}.npy')\n",
    "    \n",
    "    results = []\n",
    "    for _ in range(epochs):\n",
    "        history = model.fit(x_tr, y_tr, validation_data = (x_val, y_val),\n",
    "                            batch_size = batch_size,\n",
    "                            callbacks = [ReportCheckpointCallback(metrics = ['val_mse']), ckp, es])\n",
    "        results.append(history.history)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_95099/2719188123.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['target'] = scaler.fit_transform(train_df[['close']])\n",
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_95099/2719188123.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_df['target'] = scaler.transform(valid_df[['close']])\n",
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_95099/2719188123.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['target_ret'] = train_df['close'].pct_change(1)\n",
      "/var/folders/yn/2f068kxj3tx1xbtcj5w0tnnm0000gn/T/ipykernel_95099/2719188123.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_df['target_ret'] = valid_df['close'].pct_change(1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "train_df['target'] = scaler.fit_transform(train_df[['close']])\n",
    "valid_df['target'] = scaler.transform(valid_df[['close']])\n",
    "\n",
    "train_df['target_ret'] = train_df['close'].pct_change(1)\n",
    "valid_df['target_ret'] = valid_df['close'].pct_change(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "horizon = 100\n",
    "for lookback in range(100, 600, 100):\n",
    "    for type in ['minmax', 'ret']:\n",
    "        x_tr, y_tr = prep_time_series(train_df['target'], lookback = lookback, horizon = horizon)\n",
    "        x_val, y_val = prep_time_series(valid_df['target'], lookback = lookback, horizon = horizon)\n",
    "        x_tr, y_tr = prep_time_series(train_df['target_ret'], lookback = lookback, horizon = horizon)\n",
    "        x_val, y_val = prep_time_series(valid_df['target'], lookback = lookback, horizon = horizon)\n",
    "\n",
    "        np.save(f'../data/ray/x_tr_{lookback}_{type}.npy', x_tr)\n",
    "        np.save(f'../data/ray/y_tr_{lookback}_{type}.npy', y_tr)\n",
    "        np.save(f'../data/ray/x_val_{lookback}_{type}.npy', x_val)\n",
    "        np.save(f'../data/ray/y_val_{lookback}_{type}.npy', y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 08:15:28,102\tERROR services.py:1329 -- Failed to start the dashboard , return code 1\n",
      "2023-12-05 08:15:28,105\tERROR services.py:1354 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2023-12-05 08:15:28,107\tERROR services.py:1398 -- \n",
      "The last 20 lines of /tmp/ray/session_2023-12-05_08-15-25_702261_4078/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/dashboard/utils.py\", line 134, in get_all_modules\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/dashboard/utils.py\", line 121, in get_all_modules\n",
      "    importlib.import_module(name)\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/dashboard/modules/test/test_agent.py\", line 6, in <module>\n",
      "    import ray.dashboard.modules.test.test_utils as test_utils\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/dashboard/modules/test/test_utils.py\", line 3, in <module>\n",
      "    import async_timeout\n",
      "ModuleNotFoundError: No module named 'async_timeout'\n",
      "2023-12-05 08:15:28,109\tWARNING utils.py:581 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2023-12-05 08:15:28,110\tWARNING utils.py:593 -- Ray currently does not support initializing Ray with fractional cpus. Your num_cpus will be truncated from 11.9 to 11.\n",
      "2023-12-05 08:15:29,315\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "\u001B[33m(raylet)\u001B[0m [2023-12-05 08:15:30,225 E 4680 4727] (raylet) agent_manager.cc:70: The raylet exited immediately because one Ray agent failed, agent_name = dashboard_agent/424238335.\n",
      "\u001B[33m(raylet)\u001B[0m The raylet fate shares with the agent. This can happen because\n",
      "\u001B[33m(raylet)\u001B[0m - The version of `grpcio` doesn't follow Ray's requirement. Agent can segfault with the incorrect `grpcio` version. Check the grpcio version `pip freeze | grep grpcio`.\n",
      "\u001B[33m(raylet)\u001B[0m - The agent failed to start because of unexpected error or port conflict. Read the log `cat /tmp/ray/session_latest/logs/{dashboard_agent|runtime_env_agent}.log`. You can find the log file structure here https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure.\n",
      "\u001B[33m(raylet)\u001B[0m - The agent is killed by the OS (e.g., out of memory).\n",
      "[2023-12-05 08:15:30,409 E 4078 4769] core_worker.cc:592: :info_message: Attempting to recover 1 lost objects by resubmitting their tasks. To disable object reconstruction, set @ray.remote(max_retries=0).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 20\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\n\u001B[1;32m      6\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_generic_neurons\u001B[39m\u001B[38;5;124m\"\u001B[39m : [\u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m400\u001B[39m, \u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m600\u001B[39m, \u001B[38;5;241m700\u001B[39m],\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_generic_stacks\u001B[39m\u001B[38;5;124m'\u001B[39m : [\u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m40\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m60\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhorizon\u001B[39m\u001B[38;5;124m'\u001B[39m : \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m     18\u001B[0m }\n\u001B[0;32m---> 20\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclose\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m valid \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfrom_pandas(valid_df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[1;32m     23\u001B[0m scaling_config \u001B[38;5;241m=\u001B[39m ScalingConfig(num_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m, use_gpu \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/ray/data/read_api.py:2043\u001B[0m, in \u001B[0;36mfrom_pandas\u001B[0;34m(dfs)\u001B[0m\n\u001B[1;32m   2041\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39menable_tensor_extension_casting:\n\u001B[1;32m   2042\u001B[0m     dfs \u001B[38;5;241m=\u001B[39m [_cast_ndarray_columns_to_tensor_extension(df\u001B[38;5;241m.\u001B[39mcopy()) \u001B[38;5;28;01mfor\u001B[39;00m df \u001B[38;5;129;01min\u001B[39;00m dfs]\n\u001B[0;32m-> 2043\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfrom_pandas_refs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdfs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/ray/data/read_api.py:2089\u001B[0m, in \u001B[0;36mfrom_pandas_refs\u001B[0;34m(dfs)\u001B[0m\n\u001B[1;32m   2087\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39menable_pandas_block:\n\u001B[1;32m   2088\u001B[0m     get_metadata \u001B[38;5;241m=\u001B[39m cached_remote_fn(get_table_block_metadata)\n\u001B[0;32m-> 2089\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mget_metadata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremote\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdfs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2090\u001B[0m     logical_plan \u001B[38;5;241m=\u001B[39m LogicalPlan(FromPandas(dfs, metadata))\n\u001B[1;32m   2091\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m MaterializedDataset(\n\u001B[1;32m   2092\u001B[0m         ExecutionPlan(\n\u001B[1;32m   2093\u001B[0m             BlockList(dfs, metadata, owned_by_consumer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2097\u001B[0m         logical_plan,\n\u001B[1;32m   2098\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py:24\u001B[0m, in \u001B[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mauto_init_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     23\u001B[0m     auto_init_ray()\n\u001B[0;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py:103\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py:2557\u001B[0m, in \u001B[0;36mget\u001B[0;34m(object_refs, timeout)\u001B[0m\n\u001B[1;32m   2552\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2553\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject_refs\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must either be an ObjectRef or a list of ObjectRefs.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2554\u001B[0m     )\n\u001B[1;32m   2556\u001B[0m \u001B[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001B[39;00m\n\u001B[0;32m-> 2557\u001B[0m values, debugger_breakpoint \u001B[38;5;241m=\u001B[39m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_refs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2558\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(values):\n\u001B[1;32m   2559\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, RayError):\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py:769\u001B[0m, in \u001B[0;36mWorker.get_objects\u001B[0;34m(self, object_refs, timeout)\u001B[0m\n\u001B[1;32m    763\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    764\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to call `get` on the value \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobject_ref\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    765\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhich is not an ray.ObjectRef.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    766\u001B[0m         )\n\u001B[1;32m    768\u001B[0m timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 769\u001B[0m data_metadata_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcore_worker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_objects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobject_refs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_task_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout_ms\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    772\u001B[0m debugger_breakpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    773\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, metadata \u001B[38;5;129;01min\u001B[39;00m data_metadata_pairs:\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:3211\u001B[0m, in \u001B[0;36mray._raylet.CoreWorker.get_objects\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:449\u001B[0m, in \u001B[0;36mray._raylet.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ray.tune import TuneConfig\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "import ray\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"num_generic_neurons\" : [200, 400, 500, 600, 700],\n",
    "    'num_generic_stacks' : [30, 40, 50, 60],\n",
    "    'num_generic_layers' : [3, 4, 5, 6],\n",
    "    'num_trend_neurons' : [128, 256, 512],\n",
    "    'num_trend_stacks' : [3, 4, 5, 6, 7],\n",
    "    'num_trend_layers' : [4, 6, 8],\n",
    "    'polynomial_term' : [2, 3, 4],\n",
    "    'loss' : 'mse',\n",
    "    'lr' : 1e-3,\n",
    "    'lookback' : 200,\n",
    "    'horizon' : 100\n",
    "}\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers = 10, use_gpu = True)\n",
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker = train_func,\n",
    "    train_loop_config = {\"num_epochs\"},\n",
    "    scale_config = scaling_config,\n",
    "    datasets={\"train\": train,\n",
    "              \"valid\" : valid}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 200\n",
    "horizon = 100\n",
    "x_tr, y_tr = prep_time_series(df['close'], lookback = lookback, horizon = horizon)\n",
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker = \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    lookback = config['lookback']\n",
    "    horizon = 100\n",
    "    train_dataset = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_const is (68187, 50), x_tr is (68187, 60), y_tr is (68187, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 22:26:13.865844: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - ETA: 0s - loss: nan - mse: nanWARNING:tensorflow:Can save best model only with val_action_mse available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_action_mse` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "17/17 [==============================] - 138s 7s/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/100\n",
      " 1/17 [>.............................] - ETA: 1:17 - loss: nan - mse: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 28\u001B[0m\n\u001B[1;32m     22\u001B[0m ckp \u001B[38;5;241m=\u001B[39m ModelCheckpoint(ckp_path, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_action_mse\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     23\u001B[0m                               save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, save_weights_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     24\u001B[0m es \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_action_mse\u001B[39m\u001B[38;5;124m'\u001B[39m, min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     25\u001B[0m                     baseline\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_tr_const\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_val_const\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mckp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mes\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m hist \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(history\u001B[38;5;241m.\u001B[39mhistory)\n\u001B[1;32m     33\u001B[0m score \u001B[38;5;241m=\u001B[39m hist[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_action_mse\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmin()\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/keras/engine/training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/anaconda3/envs/python310/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "batch_size = 4096\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, train_df[f'target_5m'], groups)):\n",
    "    x_train, x_valid = train_df['target_5m'].iloc[train_idx], train_df['target_5m'].iloc[val_idx]\n",
    "\n",
    "    min_train, max_train = min(train_df['open_time'].iloc[train_idx]).to_pydatetime(), max(\n",
    "                train_df['open_time'].iloc[train_idx]).to_pydatetime()\n",
    "    min_valid, max_valid = min(train_df['open_time'].iloc[val_idx]).to_pydatetime(), max(\n",
    "                train_df['open_time'].iloc[val_idx]).to_pydatetime()\n",
    "\n",
    "    x_tr, y_tr = prep_time_series(x_train, lookback = lookback, horizon = horizon)\n",
    "    x_val, y_val = prep_time_series(x_valid, lookback = lookback, horizon = horizon)\n",
    "\n",
    "    cutoff_tr, cutoff_val = x_train.shape[0] - x_tr.shape[0], x_valid.shape[0] - x_val.shape[0]\n",
    "    x_tr_const, x_val_const = train_df[train_features_test].iloc[train_idx], train_df[train_features_test].iloc[val_idx]\n",
    "    x_tr_const, x_val_const = x_tr_const.iloc[cutoff_tr:, :], x_val_const.iloc[cutoff_val:, :]\n",
    "\n",
    "    print(f'Shape of X_const is {x_tr_const.shape}, x_tr is {x_tr.shape}, y_tr is {y_tr.shape}')\n",
    "\n",
    "    ckp_path = f'../output/{directory}/NBEATS_MSE_{fold}_returns{horizon}m_{lookback}m_{date}.hdf5'\n",
    "    model = create_nbeat_mlp(**params)\n",
    "    ckp = ModelCheckpoint(ckp_path, monitor='val_action_mse', verbose=0,\n",
    "                                  save_best_only=True, save_weights_only=True, mode='min')\n",
    "    es = EarlyStopping(monitor='val_action_mse', min_delta=1e-4, patience=10, mode='min',\n",
    "                        baseline=None, restore_best_weights=True, verbose=0)\n",
    "\n",
    "\n",
    "    history = model.fit([x_tr, x_tr_const.values], y_tr,\n",
    "                        validation_data = ([x_val, x_val_const.values], y_val),\n",
    "                        epochs = 100, batch_size = batch_size, callbacks = [ckp, es])\n",
    "\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    score = hist['val_action_mse'].min()\n",
    "    print(f'Fold {fold} MSE:\\t', score)\n",
    "    scores.append(score)\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}