{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from kerasbeats import prep_time_series, NBeatsModel\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_nbeat_mlp(num_columns, num_labels, lookback, horizon, hidden_units, dropout_rates, batch_size, ls=1e-2, lr=1e-3, ):\n",
    "    nbeats = NBeatsModel(model_type = 'generic', lookback = lookback, horizon = horizon,\n",
    "                         learning_rate = lr, batch_size = batch_size,\n",
    "                         num_generic_neurons = hidden_units[0]) # set as default\n",
    "    nbeats.build_layer()\n",
    "    time_input = keras.layers.Input(shape = (lookback * horizon, ))\n",
    "    x_nb = nbeats.model_layer(time_input)\n",
    "\n",
    "    xcons = keras.layers.Input(shape = (num_columns, ))\n",
    "    x = keras.layers.Concatenate()([xcons, x_nb])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "\n",
    "    for i in range(1, len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('swish')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i])(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(num_labels, name = 'action')(x)\n",
    "    model = tf.keras.models.Model(inputs = [time_input, xcons], outputs = out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss = {'action' : tf.keras.losses.MeanSquaredError()},\n",
    "                  metrics = {'action' : tf.metrics.MeanSquaredError(name = 'mse')})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import tscv\n",
    "\n",
    "def generate_label(df, threshold = 0.002):\n",
    "    df['label'] = 0\n",
    "    df.loc[(df['target_15m'] <= -1*threshold), 'label'] = 1\n",
    "    df.loc[(df['target_15m'] >= threshold), 'label'] = 2\n",
    "    return df\n",
    "\n",
    "def get_na_features(df, train_features):\n",
    "    tmp = pd.DataFrame(df[train_features].isnull().sum())\n",
    "    tmp = tmp[tmp[0] > 0].reset_index()\n",
    "    tmp.columns = ['feat', 'cnt']\n",
    "    tmp = tmp.sort_values('cnt')\n",
    "    feat_groups = dict(tmp.groupby('cnt')['feat'].agg(lambda x: list(x)))\n",
    "    return feat_groups"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def normalize_columns_infer(df, means, stds):\n",
    "    features = means.index.tolist()\n",
    "    for feature in features:\n",
    "        mean = means.loc[feature]\n",
    "        std = stds.loc[feature]\n",
    "        df[feature] = (df[feature] - mean) / std\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "directory = 'spot_data_11_25'\n",
    "date = '11_25'\n",
    "lib = Path(f\"../output/{directory}\").mkdir(parents=True, exist_ok=True)\n",
    "window = 30\n",
    "file = f'target_{window}m_feature.csv'\n",
    "corr = pd.read_csv(f'../output/feature_corr/{file}', header = 0, index_col = 0)\n",
    "\n",
    "train_features = corr.iloc[:50].index.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train = False\n",
    "df = pd.read_feather('../data/df_btc_with_features_5m_spot.feather')\n",
    "\n",
    "df = df.loc[df['token'] == 'BTCUSDT'].reset_index(drop = True)\n",
    "\n",
    "df = df.sort_values(by='open_time', ignore_index=True)\n",
    "\n",
    "df['close_5m'] = df['close'].shift(-1)\n",
    "df['close_t'] = df['close'].copy()\n",
    "\n",
    "start_time = df['open_time'].min()\n",
    "end_time = df['open_time'].max()\n",
    "dates = df['open_time'].unique()\n",
    "n = len(dates)\n",
    "train_idx = int(0.7 * n)\n",
    "valid_idx = int(0.9 * n)\n",
    "train_end = dates[train_idx]\n",
    "valid_end = dates[valid_idx]\n",
    "\n",
    "train_df = df.loc[df['open_time'] < train_end].reset_index(drop=True)\n",
    "valid_df = df.loc[(train_end <= df['open_time']) & (df['open_time'] < valid_end)].reset_index(drop=True)\n",
    "\n",
    "train_df = pd.concat([train_df, valid_df], axis = 0)\n",
    "\n",
    "test_df = df.loc[(df['open_time'] >= valid_end)].reset_index(drop=True)\n",
    "\n",
    "valid_df = test_df.copy()\n",
    "\n",
    "groups = pd.factorize(\n",
    "    train_df['open_time'].dt.day.astype(str) + '_' + train_df['open_time'].dt.month.astype(str) + '_' + train_df[\n",
    "        'open_time'].dt.year.astype(str))[0]\n",
    "\n",
    "cv = tscv.PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    group_gap=31,\n",
    ")\n",
    "\n",
    "from joblib import load, dump\n",
    "date = f'11_23'\n",
    "directory = f'spot_data_11_25'\n",
    "lookback = 5\n",
    "horizon = 100\n",
    "means = load(f'../output/{directory}/means_nbeats_huber_l={lookback}_h={horizon}.joblib')\n",
    "std = load(f'../output/{directory}/std_return_nbeats_l={lookback}_h={horizon}joblib')\n",
    "train_features_test = load(\n",
    "    f'../output/{directory}/train_features_test_return_nbeats_l={lookback}_h={horizon}.joblib')\n",
    "\n",
    "valid_df = normalize_columns_infer(valid_df, means, std)\n",
    "\n",
    "lookback = 5\n",
    "horizon = 100\n",
    "batch_size = 4096\n",
    "params = {'num_columns': len(train_features_test),\n",
    "          'num_labels': 1,\n",
    "          'lookback' : lookback,\n",
    "          'horizon' : horizon,\n",
    "          'batch_size' : batch_size,\n",
    "          'hidden_units': [300, 200, 448, 256],\n",
    "          'dropout_rates': [0.42409238408801436, 0.10431484318345882,\n",
    "                            0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],\n",
    "          'ls': 0,\n",
    "          'lr': 1e-3,\n",
    "          }\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}